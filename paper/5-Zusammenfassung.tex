\section{Zusammenfassung}


Diese Arbeit hat ein rekursives semantisches Ähnlichkeitsmaß für ein Informationsnetzwerk von wissenschaftlichen Publikationen und ihren Metadaten entworfen und implementiert.
Innerhalb des Netzwerkes wurden Publikationen sowie die vorhanden Metadaten als Knoten modelliert.
Zur Evaluation des entwickelten Maßes wurde ein Clusterverfahren auf die berechneten Ähnlichkeitswerte angewandt und mit im Datensatz vergebenen MSC-Klassen mit dem Ziel verglichen, dass ähnliche Publikationen auch in ähnliche MSC-Klassen gehören.
Das Ähnlichkeitsmaß und anschließend das Clusterverfahren wurde auf einen Testdatensatz aus $3095$ ausgewählten Publikationen des \textit{Zentralblatt Mathematik} angewandt.
Das entwickelte Maß ist unter der Annahme entstanden, dass zwei Publikationen ähnlich sind, wenn sie innerhalb des Netzwerks über ähnliche Metadaten verbunden sind.
\\
\\
Die experimentellen Ergebnisse des Clusterverfahrens haben gezeigt, dass sich das semantische Ähnlichkeitsmaß besser für die Ähnlichkeitsberechnung zweier Publikationen eignet als das strukturelle Maß \textit{C-Rank}, das nur auf Zitationen basiert, eignet.
\textit{C-Rank} ist nicht in der Lage, brauchbare Ähnlichkeitswerte zu liefern, wenn keine vollständige Referenzlisten der untersuchten Publikationen vorliegen.
Das entwickelte Verfahren hingegen verwendet auch andere Metadaten, die weitere wichtige Informationen über die wissenschaftlichen Arbeiten liefern.
Diese sollten bei einer Ähnlichkeitsanalyse der Publikationen nicht vernachlässigt werden.
\\
\\
Das Verfahren hat, wie andere verwandte Ansätze auch, eine sehr komplexe Laufzeit.
Dadurch war es im Rahmen dieser Arbeit leider nicht möglich, das Verfahren auf dem kompletten \textit{zmath}-Datensatz zu testen.


\subsection{Ausblick}
Das in dieser Arbeit vorgeschlagene semantische Ähnlichkeitsmaß kann in verschiedenen Richtungen optimiert und weiterentwickelt werden.
\\
\\
Wie auch durch die Evaluation bekräftigt, ist es von entscheidender Bedeutung, dass die semantische Ähnlichkeit für einen gesamten, nicht verkleinerten Datenatz begerechnet wird.
Ein Nachteil des entworfenen Algorithmus, der seine Anwendung auf große Datenmengen maßgeblich erschwert, ist seine Laufzeitkomplexität $\mathcal{O}(n^4)$.
Eine wertvolle Optimierung wäre die Parallelisierung der Berechnungen.
Die Frage, ob der Algorithmus parallelisierbar ist, ist offen und muss näher untersucht werden.
\cite{Li2010} schlagen ein nicht iteratives Verfahren für die Berechnung von \textit{SimRank} vor, das die Berechnung der Ähnlichkeiten wesentlich beschleunigt.
Es scheint leider in seiner ursprüglichen Form nicht anwendbar für die Berechnung der semantischen Ähnlichkeit in einem heterogenen Publikationsnetzwerk, das verschiedene Arten von Knoten beinhaltet.
Die Möglichkeit, ein nicht iteratives Verfahren für die Berechnung der semantischen Ähnlichkeit, das auf \cite{Li2010} basiert, zu entwickeln, kann untersucht werden.
\\
\\
Eine andere Erweiterung des vorgeschlagenen Algorithmus für semantische Ähnlichkeit wäre die Berücksichtigung weiterer verfügbarer Metadaten wie z.B. Titel oder Abstract.
Der Algorithmus kann dann mit textbasierten Ähnlichkeitsmetriken, die die Ähnlichkeit von Titel und Abstract zweier Publikationen ermitteln können, kombiniert werden.
Darüber hinaus können bei mathematischen Publikationen auch zusätzliche Komponenten wie Formeln, Theoreme oder Diagramme in das Ähnlichkeitsmaß miteinbezogen werden.
Das entwickelte Verfahren besitzt also ausreichend Potential zur Weiterentwicklung.

%nochmal betonen, dass durch trimming informationen verloren gehen
% bessere rechner, mehr zeit wird gebraucht
% optimieren des algorithmus? parallelisieren
%% publikationsnetzwerk auslagern, nur ähnlichkeitsmatrix im arbeitsspeicher
%% wenn G zu groß, kann mans extern, außerhalb des Hauptspeichers auslagern (z.b. Graphdatenbank) (die Ähnlichkeitsmatrix, egal welche Struktur für ihre Repräsentation gewählt wird, wird erstmal einfachshalber im Arbeitsspeicher behalten
% das eigentliche (größere) Problem ist die Laufzeit -- es können Verfahren gesucht werden, um die zu optimieren / Teile des Algorithmus zu parallelisieren
% anderer ansatz, der das gesamte netzwerk betrachet (und alle metadaten)

% vlt andere daten miteinbeziehen: den ansatz mit einem textbasierten für title/abstract kombinieren
% vlt auch formeln, theoreme, diagramme auswerten



%----------------------------------------------
%* was haben wir gemacht
%* was gewinnen wir durch semantische Analyse von Metadaten
%* hinweis auf weiterführende recherche

% Koennen wir auch weitere Daten analysieren? Auf anderen Weisen (nicht semantisch)?
% zb mathematische formeln/theoreme/diagramme, die im text vorkommen
% Wie kann man das Ähnlichkeitsmaß anders/besser definieren?

% man kann das semantische Ähnlichkeitsmaß mit einem textbasierten kombinieren, das die Ähnlichkeit zwischen Title/Abstracts auswertet, und diese dann auch für die Semantische Ähnlichkeit nutzen
% Levenshtein distance: einfache Distanz zwischen 2 Strings/Texten \cite ???
% basiert auf die Anzahl von Einfügungen, Löschungen, Ersetzungen von Buchstaben, die gebraucht werden, um einen String in einen anderen zu transformieren
% extrem unpraktisch: wir können nicht für tausende von Dokumenten, mit mehreren Seiten Text die Levenshteindistanz messen..
% fragwürdig, ob brauchbare Ergebnisse rauskommen (wobei man könnte vlt so was schon für das Bauen einer Plagiatsoftware einsetzen..)
% kann vlt für das vergleichen von Abstracts/Titel genutzt werden


% man kann doch als weiterführende Forschung eben solche Anwendungen bauen, die auf so einem Ähnlichkeitsmaß beruhen
% man kann das Maß auch dafür nutzen, zeitliche Analyse der Entwicklung der Wissenschaft in bestimmten Forschungsfelder/zu bestimmten Forschungsthemen zu entwerfen


%In a general way,
%
%restate your topic and why it is important,
%restate your thesis/claim,
%address opposing viewpoints and explain why readers should align with your position,
%call for action or overview future research possibilities.
%
%from my specific topic to more general matters
%say what you have already said but do it quickly, sharply and in different words
