\section{Zusammenfassung}


Diese Arbeit hat ein semantisches Ähnlichkeitsmaß für wissenschaftliche Publikationen basierend auf deren Metadaten entworfen und dieses auf einen Testdatensatz aus $3095$ Publikationen des \textit{Zentralblatt Mathematik} angewandt.
Die experimentellen Ergebnisse haben gezeigt, dass sich das semantische Ähnlichkeitsmaß besser für die Ähnlichkeitsberechnung zweier Publikationen als das strukturelle Maß \textit{C-Rank} eignet, das nur auf Zitationen basiert.
\textit{C-Rank} ist nicht in der Lage brauchbare Ähnlichkeitswerte zu liefern, wenn keine vollständige Referenzlisten der untersuchten Publikationen vorliegen.
Andere Metadaten bringen wichtige Informationen über die wissenschaftlichen Arbeiten und sollen bei einer Ähnlichkeitsanalyse der Publikationen nicht vernachlässigt werden.

\subsection{Ausblick}
Das in dieser Arbeit vorgeschlagene semantische Ähnlichkeitsmaß kann in verschiedenen Richtungen optimiert und weiterentwickelt werden.
\\
\\
Wie auch durch die Evaluation bekräftigt, ist es von entscheidender Bedeutung, dass die semantische Ähnlichkeit für einen gesamten, nicht verkleinerten Datenatz ausgerechnet wird.
Eine der Schwachstellen des entworfenen Algorithmus, die seine Anwendung auf große Datenmengen maßgeblich erschwert, ist seine Laufzeitkomplexität $\mathcal{O}(n^4)$.
Eine wertvolle Optimierung wäre die Parallelisierung der Berechnungen.
Die Frage, ob der Algorithmus parallelisierbar ist, ist offen und muss näher untersucht werden.
\cite{Li2010} schlagen ein nicht iteratives Verfahren für die Berechnung von \textit{SimRank} vor, das die Berechnung der Ähnlichkeiten wesentlich beschleunigt.
Es scheint leider in seiner ursprüglichen Form nicht anwendbar für die Berechnung der semantischen Ähnlichkeit in einem heterogenen Publikationsnetzwerk, das verschiedene Arten von Knoten beinhaltet.
Die Möglichkeit, ein nicht iteratives Verfahren für die Berechnung der semantischen Ähnlichkeit, das auf \cite{Li2010} basiert, zu entwickeln, kann untersucht werden.
\\
\\
Eine andere denkbare Erweiterung des vorgeschlagenen Algorithmus für semantische Ähnlichkeit wäre die Berücksichtigung weiterer verfügbarer Metadaten wie z.B. Titel oder Abstract.
Der Algorithmus kann dann mit textbasierten Ähnlichkeitsmetriken, die die Ähnlichkeit von Titel und Abstract zweier Publikationen ermitteln können, kombiniert werden.
Darüber hinaus können bei mathematischen Publikationen auch zusätzliche Komponenten wie Formeln, Theoreme oder Diagramme in das Ähnlichkeitsmaß miteinbezogen werden.


%nochmal betonen, dass durch trimming informationen verloren gehen
% bessere rechner, mehr zeit wird gebraucht
% optimieren des algorithmus? parallelisieren
%% publikationsnetzwerk auslagern, nur ähnlichkeitsmatrix im arbeitsspeicher
%% wenn G zu groß, kann mans extern, außerhalb des Hauptspeichers auslagern (z.b. Graphdatenbank) (die Ähnlichkeitsmatrix, egal welche Struktur für ihre Repräsentation gewählt wird, wird erstmal einfachshalber im Arbeitsspeicher behalten
% das eigentliche (größere) Problem ist die Laufzeit -- es können Verfahren gesucht werden, um die zu optimieren / Teile des Algorithmus zu parallelisieren
% anderer ansatz, der das gesamte netzwerk betrachet (und alle metadaten)

% vlt andere daten miteinbeziehen: den ansatz mit einem textbasierten für title/abstract kombinieren
% vlt auch formeln, theoreme, diagramme auswerten



%----------------------------------------------
%* was haben wir gemacht
%* was gewinnen wir durch semantische Analyse von Metadaten
%* hinweis auf weiterführende recherche

% Koennen wir auch weitere Daten analysieren? Auf anderen Weisen (nicht semantisch)?
% zb mathematische formeln/theoreme/diagramme, die im text vorkommen
% Wie kann man das Ähnlichkeitsmaß anders/besser definieren?

% man kann das semantische Ähnlichkeitsmaß mit einem textbasierten kombinieren, das die Ähnlichkeit zwischen Title/Abstracts auswertet, und diese dann auch für die Semantische Ähnlichkeit nutzen
% Levenshtein distance: einfache Distanz zwischen 2 Strings/Texten \cite ???
% basiert auf die Anzahl von Einfügungen, Löschungen, Ersetzungen von Buchstaben, die gebraucht werden, um einen String in einen anderen zu transformieren
% extrem unpraktisch: wir können nicht für tausende von Dokumenten, mit mehreren Seiten Text die Levenshteindistanz messen..
% fragwürdig, ob brauchbare Ergebnisse rauskommen (wobei man könnte vlt so was schon für das Bauen einer Plagiatsoftware einsetzen..)
% kann vlt für das vergleichen von Abstracts/Titel genutzt werden


% man kann doch als weiterführende Forschung eben solche Anwendungen bauen, die auf so einem Ähnlichkeitsmaß beruhen
% man kann das Maß auch dafür nutzen, zeitliche Analyse der Entwicklung der Wissenschaft in bestimmten Forschungsfelder/zu bestimmten Forschungsthemen zu entwerfen


%In a general way,
%
%restate your topic and why it is important,
%restate your thesis/claim,
%address opposing viewpoints and explain why readers should align with your position,
%call for action or overview future research possibilities.
%
%from my specific topic to more general matters
%say what you have already said but do it quickly, sharply and in different words
