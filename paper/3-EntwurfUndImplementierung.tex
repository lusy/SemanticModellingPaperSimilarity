\section{Entwurf und Implementierung}

\subsection{Analyse des zugrundeliegenden Datensatzes}
% Erklaerung was das Zentralblatt Mathematik ist - siehe homepage
% Beschreibung wie der Datensatz aufgebaut ist, welche Besonderheiten sind aufgefallen
% Beispiel zeigen
% Beschreibung der Eigenschaften (bisschen statistische Analysen?)
% vlt eine Auflistung davon, welche Daten arbiträr sind (nicht immer ausgefüllt im Datensatz)

Als Ausgangspunkt für den Entwurf und Evaluierung des semantischen Ähnlichkeitsmaßes wird ein Datensatz vom Zentralblatt Mathematik,
\footnote{Das Zentralblatt Mathematik (ZMath) ist die größte wissenschaftliche Datenbank, die Metadaten, Abstracts und Reviews auf den Gebieten der reinen und angewandten Mathematik enthält.}
 der die Metadaten zu $2,907,086$ Publikationen enthält, eingesetzt.

Tabelle \ref{tab:metadata} gibt einen Überblick über die zu einer Publikation möglichen Einträgen.

\begin{table}[H]
\centering % used for centering table
\begin{tabular}{| c | l | l |}
		\hline
		\textbf{Bezeichner} &\textbf{Bedeutung} &\textbf{Inhalt}\\
		\hline
		\textit{:id:} & & \textit{eindeutiger Identifier} \\
		:an: & Accession number & durch das ZMath vergebene eindeutige Identifikationsnummer\\
		:au: & Authors & die Autoren einer Publikation \\
		:ai: & & eindeutige Stringrepräsentation von jedem Autor \\
		:ti: & Title & Überschrift der Publikation \\
		\textit{:so:} & \textit{Source} & \textit{Quelle, wo die Publikation erschienen ist} \\
		\textit{:py:} & \textit{Publication Year} & \textit{das Jahr, in dem die Publikation erschienen ist} \\
		:cc: & & MSC Klassen, die der Publikation zugeordnet worden sind \\
        :ab/en: & Abstract English & Die Kurzzusammenfassung der Publikation auf Englisch\\
        :la: & Language & auf welcher Sprache ist die Publikation verfügbar\\
        :ut: & & englische Keywords\\
        :ci: & Citations & Arbeiten, die die Publikation zitiert\\
        :rv/en: & Reviewer & die Reviewer einer Publikation\\
		\hline
\end{tabular}
\caption{Die Metadaten vom ZMATH Datensatz. Alle \textit{Kursiveinträge} sind obligatorisch.}
\label{tab:metadata}
\end{table}

Dazu ist noch zu erwähnen, dass zu einer Publikation mehrere Autoren/Autorinnen, MSC Klassen, Sprachen, Keywords und Zitationen möglich sind.
\\
\\
Der Datensatz hat ferner die folgenden Merkmale:\\
Jede Publikation hat im Schnitt $1.68$ Autoren.
Die größte Anzahl an Wissenschaftler und Wissenschaftlerinnen, die zusammen eine Arbeit publiziert haben, ist 38.
Die produktivsten Autoren sind Paul Erdös mit $1208$ Veröffentlichungen, Edoardo Ballico ($1100$ Publikationen), Lucien Godeaux ($794$ Publikationen) und Leonard Carlitz ($735$ Publikationen).
Eine Verteilung der Autorenzahlen im $zmath$-Datensatz ist auf Abbildung \ref{fig:authorFreq} zu sehen\footnote{Publikationen, wo die Anzahl der Autoren, Zitationen, Keywords oder MSC-Klassen null ist, werden in den Diagrammen nicht berücksichtigt}.
\\
\\
Das Paper mit dem größten Literaturverzeichnis zitiert 38 andere Arbeiten.
Jede Publikation hat im Schnitt 0.27 Zitationen.
Tabelle \ref{tab:citations} stellt die am öftesten zitierten Publikationen und die Anzahl ihrer Referenzen dar,
die Häufigkeitsverteilung der Zitationen im Datensatz ist in Abbildung \ref{fig:citationFreq} dargestellt.

\begin{table}[h]
\centering
\begin{tabular}{| l | p{8cm} | c |}
    \hline
    \textbf{:an:} & \textbf{ Titel/Quelle} & \textbf{Anzahl Referenzen}\\
    \hline
    $Zbl 0707.68001$ & IJCA I-89. International joint conference on artificial intelligence, Detroit, MI, USA, August 20-25, 1989. Proceedings. Vol. 1 u. 2.&257\\
    \hline
    $Zbl 0425.00034$ & Proceedings of the 1978 IEEE conference on decision and control, including the 17th symposium on adaptive processes. IEEE Control Systems Society, January 10-12, 1979, Islandia Hyatt House Hotel, San Diego, California. & 212\\
    \hline
    $Zbl 0741.68016$ & IJCAI 91, Proceedings of the 12th International Conference on Artificial Intelligence. Sydney, Australia, 24-30 August 1991. Vol. 1-2. & 183\\
    \hline
    $Zbl 0657.00005$ & Proceedings of the International Congress of Mathematicians (ICM), August 3-11, 1986, Berkeley, California. Volumes $1+2$. & 159\\
    \hline
    $Zbl 0624.00010$ & Nonlinear oscillations. Proceedings of the 11th International Conference on Nonlinear Oscillations, Budapest, August 17-23, 1987. & 156\\
    \hline
\end{tabular}
\caption{Die am häufigsten zitierten Papers}
\label{tab:citations}
\end{table}

Im Durchschnitt wurden pro Publikation 3 Keywords vergeben.
Die maximale Anzahl von Keywords für eine Arbeit ist 219, die nächst große - 162.
Tabelle \ref{tab:keywords} beinhaltet die am häufigsten vergebenen Keywords.
Häufigkeitsverteilung der Keywords kann Abbildung \ref{fig:keywordFreq} entnommen weden.

\begin{table}[h]
\centering
\begin{tabular}{| l | c |}
		\hline
		\textbf{Keyword} &\textbf{Anzahl Papers} \\
		\hline
		convergence & $18,872$\\
		stability & $16,766$ \\
		functional analysis & $15,049$ \\
		fluid machanics & $14,185$ \\
		numerical examples & $13,874$\\
	    \hline
\end{tabular}
\caption{Die häufigsten Keywords}
\label{tab:keywords}
\end{table}


Es gibt Papers auf 69 verschiedenen Sprachen.
$2,897,259$ der Publikationen wurden auf einer Sprache veröffentlicht, $9,588$ auf 2, 33 auf 4 und eine Publikation ist auf 7 Sprachen verfügbar.
Die am häufigsten vorkommenden Sprachen sind: Englisch (mit $2,370,288$ Publikationen), Russisch (mit $180,335$), Französisch ($100,575$), Deutsch ($91,510$) und Chinesisch ($77,924$).
\\
\\
Im Durchschnitt hat jede Arbeit 2 MSC Klassen, die Arbeit mit den meisten Klassen hat 61.
$2,594,068$ Publikationen haben mindestens eine MSC Klasse.
Die am häufigsten vergebenen MSC Klassen sind $68U99$ (Compuer Science -> Computing methodologies and applications), $80A20$ (Classical thermodynamics, heat transfer -> Heat and mass transfer, heat flow), $93C05$ (Systems theory; control -> Control systems -> Linear systems) und $68Q25$ (Computer Science -> Theory of computing -> Analysis of algorithms and problem complexity).
Abbildung \ref{fig:mscClassFreq} stellt die Verteilung der MSC-Klassen im Datensatz dar.
\\
\\
Die Arbeiten, die der Datensatz enthält, sind in 89 verschiedenen Jahren veröffentlicht worden.
Der früheste Eintrag (eine Arbeit vom schweizerischen Mathematiker Leonard Euler) stammt vom Jahr 1796.
Es gibt auch jeweils eine Publikation von den Jahren 1879, 1914, 1924 und 1930.
1931 ist mit 4041 Veröffentlichungen das erste Jahr, das mehr oder weniger vollständig im Datensatz vermerkt ist.
Das produktivste Jahr bis jetzt war 2008 mit $102,319$ Veröffentlichungen.


\begin{figure}
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.3]{../data/statistics/authorFreq.png}
        \caption{Autorenverteilung}
        \label{fig:authorFreq}
    \end{subfigure}
    \qquad
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.3]{../data/statistics/citationFreq.png}
        \caption{Zitationsverteilung}
        \label{fig:citationFreq}
    \end{subfigure}
    \newline
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.3]{../data/statistics/keyWordFreq.png}
        \caption{Keywordverteilung}
        \label{fig:keywordFreq}
    \end{subfigure}
    \qquad
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.3]{../data/statistics/mscClassFreq.png}
        \caption{Verteilung der MSC-Klassen}
        \label{fig:mscClassFreq}
    \end{subfigure}
    \caption{Verteilungen einiger Metadaten im zmath-Datensatz}
    \label{fig:frequencies}
\end{figure}

\subsection{Modellierung des semantischen Netzes}
\label{subsec:modell}
% Wie sieht es aus?
% Welche Überlegungen gab es bei der Designentscheidung? Warum hab ich an Stellen, wo mehrere Ansätze möglich waren genau das gewählt?
% Was könnte vlt anders/besser realisiert werden
% Vlt technische Details/Grenzen/Eckdaten (Laufzeit, Speicherplatz, etc)
% Vlt Werkzeuge

% Motivation für die Modellierung:
% Ontology of Science z.b hat nen anderen Fokus;
% modelliert eine ganze Domäne von wissenschaftlichen Akteuren, Ereignissen, Einrichtungen,..
% das Modell, das sie bietet, ist für Ähnlichkeitsanalysen zwischen wissenschaftlichen Arbeiten nicht geeignet.
% Was Ontology of Science zu einer Publikation modelliert: diverse Unterklassen (Report, Thesis, ...), Author, Topic, Publication Year
% Was Ontology of Science zu einer Publikation NICHT modelliert (ist aber wichtig): Classification, Title, Keywords, Source (klar gekennzeichnet und in Relation zu der Publikation stehend), Zitationsrelationen

% Die Klassen einzeln durchgehen + die Relationen: erklären warum genau diese relevant sind und modelliert werden sollen
% erklären welche Metadaten genau für diese Arbeit von Relevanz sind
% zukünftige Möglichkeiten der Auswertung (Abstract, Title können auch nach weiterer Verabeitung ausgewertet werden) - mehr dazu in Evaluation oder Ausblick

Eins der Ziele dieser Arbeit war, eine Modellierung wissenschaftlicher Publikationen und dazu gehöriger Metadaten in der Form eines semantischen Netzes zu schaffen.
Im zweiten Teil der Arbeit soll dann von dieser semantischen Repräsentation profitiert werden, indem möglichst viele verschiedene Metadaten in die Ermittlung der Ähnlichkeit zwischen zwei Publikationen berücksichtigt werden.
\\
\\
Die bereits existierende \textit{Ontology of Science} \cite{ontosci} (vgl. Kapitel \ref{sec:semanticRepr}) scheint auf dem ersten Blick einen ähnlichen Zweck zu erfüllen, hat jedoch einen ganz anderen Fokus.
Sie modelliert eine ganze Domäne von wissenschaftlichen Akteuren, Ereignissen, Einrichtungen, Arbeiten und die dazwischen bestehenden Beziehungen.
Sie bietet ferner eine recht detaillierte Aufteilung von wissenschaftlichen Publikationen in Unterkategorien (z.B. \textit{Technical report}, \textit{Book}, \textit{Thesis}, \textit{Journal article}, etc.).
Dennoch eignet sich das Modell, das sie schafft, für Ähnlichkeitsanalysen zwischen Publikationen aufgrund von Metadaten eher schlecht.
Viele Einheiten, die für solche Analysen von großem Interesse wären, werden durch die \textit{Ontology of Science} nicht erfasst.
Einige Beispiele hierfür sind Metadaten wie Klassifikationscodes, Keywords oder Zitationen.


\subsubsection{Ontologieschema in OWL}
Aus diesen Gründen schlägt die aktuelle Arbeit die \textit{Publications Ontology} vor.
Die \textit{Publications Ontology} hat die Form eines semantischen Netzes, das mit Hilfe der Ontologiebeschreibungssprache \textit{OWL}\footnote{http://www.w3.org/TR/owl2-overview/} definiert wurde.
Die \textit{Web Ontology Language} (kurz \textit{OWL}) ist ein Standard des World Wide Web Consortiums (W3C), der die Wissensrepräsentation in der Form maschinenlesbarer Ontologien ermöglicht.
\\
\\
Wie bereits in Kapitel \ref{sec:semanticNet} erwähnt, modelliert die \textit{Publications Ontology} jede Publikation und jedes dazugehörige Metadatum als Individuen.
Alle allgemeinen Kategorien (Publikation, Autor, Quelle, etc.) werden dabei als Klassen definiert.
Die gelabelten Kanten dieses semantischen Netzes sind die Relationen zwischen einem Paper und seinen Metadaten.
Manche Klassen, bzw. die dazugehörigen Individuen, besitzen auch Attribute.
Z.B. hat jedes Individuum der Klasse \textit{Publication} das Attribut \textit{Id} und kann optional auch die Attribute \textit{Abstract}, \textit{AccessionNumber} oder \textit{TitleString} haben.

\begin{figure}
    \begin{subfigure}[h]{0.3\textwidth}
        \centering
        \includegraphics[scale=0.4]{./diagrams/classes_cut_3.png}
        \caption{Classes}
        \label{fig:pubOntoClasses}
    \end{subfigure}
    \quad
    \begin{subfigure}[h]{0.3\textwidth}
        \centering
        \includegraphics[scale=0.4]{./diagrams/object_properties_cut_3.png}
        \caption{Object Properties}
        \label{fig:pubOntoObjectProps}
    \end{subfigure}
    \quad
    \begin{subfigure}[h]{0.3\textwidth}
        \centering
        \includegraphics[scale=0.4]{./diagrams/data_properties_cut_4.png}
        \caption{Data Properties}
        \label{fig:pubOntoDataProps}
    \end{subfigure}
    \caption{Classes, Object Properties und Data Properties der \textit{Publications Ontology}}
    \label{fig:pubOntoClOPDP}
\end{figure}

Die \textit{Publications Ontology} modelliert die folgenden Klassen: \textit{Publication}, \textit{Title}, \textit{Author}, \textit{Keyword}, \textit{ClassifiationCode} (mit Unterklassen \textit{ACM\_ClassifictionCode} und \textit{MSC\_ClassificationCode}), \textit{Editor}, \textit{Reviewer}, \textit{Language}, \textit{PublicationYear} und \textit{Source} (mit Unterklassen \textit{Book}, \textit{Journal} und \textit{Proceedings})
und auch die entsprechenden, in der Regel invertierbaren, Beziehungen zwischen diesen Klassen (z.B. die Paare: \textit{hasAuthor} - \textit{isAuthorOf}, \textit{hasClassificationCode} - \textit{isClassificationCodeOf}, etc.).
Im Sinne von \textit{OWL} werden letztere als Object Properties definiert.
Object Properties beschreiben in \textit{OWL} abstrakte Rollen, die zwischen zwei Individuen halten \cite{Hitzler:2007:SW}.
Ferner werden die folgenden, für eine Publikation relevanten, Metadaten als Data Properties dargestellt:
\textit{Abstract}, \textit{Id}, \textit{TitleString} und \textit{Accession Number} (letzteres ist eine für den \textit{zmath}-Datensatz spezifische Identifikationsnummer).
Data Properties oder konkrete Rollen verbinden in \textit{OWL} Individuen mit Datenwerten \cite{Hitzler:2007:SW}.
Eine vollständige Auflistung der Klassen der \textit{Publications Ontology} sowie der Object und Data Properties bietet Abbildung \ref{fig:pubOntoClOPDP} an.
Auf Abbildung \ref{fig:pubsOnto} sind alle Klassen mit den dazugehörigen Unterklassen und die dazwischen herrschenden Beziehungen zu sehen.
Bei den Object Properties geht es in der Regel aus deren Namen hervor, zwischen Individuen welcher zwei Klassen diese halten:
z.B. stehen eine Publikation und ihr Titel in Relation \textit{hasTitle} zu einander, die inverse Relation \textit{isTitleOf} hält dann zwischen dem Titel und der Publikation.
Abbildung \ref{fig:pubsOnto_relations} zeigt die Oberklassen der \textit{Publications Ontology} mit den dazu gehörigen gelabelten Beziehungen (es wird jedoch aus ästhetischen Gründen nur eine der beiden Richtungen dargestellt).
Die Data Properties bilden stets die Beziehung zwischen einer konkreten Publikation (eines Individuums der Klasse Publikation) und einem Attribut, das zu dieser Publikation gehört, ab.

\begin{figure}[hp]
    \centering
    \includegraphics[angle=90,scale=0.5]{../deps/publications_ontology.png}
    \caption{Publications Ontology: alle Klassen und Unterklassen}
    \label{fig:pubsOnto}
\end{figure}

\begin{figure}[hpt]
    %\centering
    \includegraphics[scale=0.4]{../deps/publications_ontology_relations.png}
    \caption{Publications Ontology: Relationen zwischen den Oberklassen}
    \label{fig:pubsOnto_relations}
\end{figure}

Eine besondere Designentscheidung ist, dass die drei Object Properties \textit{hasKeywordLanguage}, \textit{hasPublicationLanguage} und \textit{hasTitleLanguage} einzeln modelliert sind.
Der Hintergrundgedanke dabei ist, dass eine Publikation oder die entsprechenden Metadaten: Keyword und Titel, auf mehreren Sprachen vorliegen können.
Diese Definition erlaubt dann, dass z.B. der englische Begriff \textit{graph theory} und der Deutsche \textit{Graphentheorie} auf das selbe Keyword abgebildet werden können, was für eine spätere Ähnlichkeitsanalyse extrem sinnvoll wäre.
\\
\\
Eine andere auffällige Besonderheit ist die Tatsache, dass sowohl die Klasse \textit{Title}, die mittels der Object Property \textit{hasTitle} mit der Klasse \textit{Publication} verbunden ist, als auch die Data Property \textit{hasTitleString} modelliert werden.
Diese Entscheidung beruht auf der Idee, dass ein Individuum der Klasse \textit{Publication} mittels \textit{hasTitleString} mit seinem exakten Titel (einer Instanz des Datentyps \textit{string}) verknüpft werden kann.
Aus diesem Stringdatenwert können dann später die Schlüsselbegriffe extrahiert werden und als ein \textit{Bag of words}\footnote{Bag of words bezeichnet in den Feldern der Information Retrieval und Natural Language Processing eine ungeordnete Menge von Wörtern} auf ein Individuum der Klasse \textit{Title} abgebildet werden.
Somit können Titel verschiedener Publikationen, die die gleichen bedeutsamen Begriffe enthalten, auf das selbe Individuum der Klasse \textit{Title} abgebildet werden.
Dieser Ansatz wäre für eine Ähnlichkeitsanalyse viel sinnvoller als ein einfaches Stringmatching auf zwei exakten Titel zu machen oder die String-Edit-Distance zwischen diesen zu bestimmen.
Das ist jedoch eine Möglichkeit, die die aktuelle Arbeit nicht mehr realisiert und die zukünftig näher untersucht werden kann.
% zukünftige Möglichkeiten der Auswertung (Abstract, Title können auch nach weiterer Verabeitung ausgewertet werden) - mehr dazu in Evaluation oder Ausblick
\\
\\
Das vorgeschlagene Ontologieschema ist möglichst allgemein gehalten, damit verschiedene Datensätze, die wissenschaftliche Publikationen beinhalten, darauf abgebildet werden können.
Bei Bedarf kann das Schema unkompliziert erweitert werden:
es können z.B. weitere Unterklassen von \textit{Source} oder \textit{ClassificationCode} definiert werden, sofern solche in dem aktuell betrachteten Datensatz vorhanden sind.


\subsubsection{GraphML}
An der Stelle wird erwähnt, dass die \textit{OWL}-Modellierung nicht die Wissensrepräsentation ist, die auch tatsächlich in der aktuellen Arbeit für die weiteren Ähnlichkeitsanalysen verwendet wird.
Anstatt dessen wird die semantische Ähnlichkeit zwischen zwei wissenschaftlichen Publikationen aufgrund von einer \textit{GraphML}-Modellierung\footnote{\textit{GraphML} ist eine auf \textit{XML} basierende Beschreibungssprache für Graphen.
Sie unterstützt ungerichtete, gerichtete, gemischte, Hyper- und Multigraphen.
Ferner können sowohl Knoten als auch Kanten beliebige Attribute zugeordnet werden.
Eine vollständige Dokumentation von \textit{GraphML} ist unter graphml.graphdrawing.org/primer/graphml-primer.htm zu finden.
} berechnet.
Die Überführung der \textit{Publications Ontology} vom \textit{OWL}-Schema ins \textit{GraphML}-Schema ist weitgehend unproblematisch, da bei der \textit{OWL}-Modellierung keine spezifische \textit{OWL}-Features benutzt werden.
\\
\\
Die Motivation hierfür ist Ressourcensparren.
Wie bereits angedeutet, beinhaltet der von dieser Arbeit benutzte Testdatensatz die Metadaten zu $2,907,086$ Publikationen.
Eine \textit{OWL}-Repräsentation der vollständigen Daten wird $8.9$ Gb groß, dagegen ist die \textit{GraphML}-Repräsentation davon nur $4.8$ Gb.
Das ist an der Stelle von besonderer Bedeutung, da der Ähnlichkeitsberechnungsalgorithmus zunächst die Gesamtdaten in den Arbeitsspeicher lädt und darauf arbeitet.
Zum Vergleich werden hier zwei Codeausschnitte aufgeführt, die die \textit{OWL}- bzw. \textit{GraphML}-Repräsentation der Beispielspublikation \textit{Publication\_123456} mit ihren Autor \textit{John Smith} und 2 Keywords \textit{graph theory} und \textit{shortest path} darstellen.

\begin{program}
\input{diagrams/pub_graphml_example}
\caption{Die \textit{GraphML}-Repräsentation}
\end{program}

\begin{program}
\input{diagrams/pub_owl_example}
\caption{Die \textit{OWL}-Repräsentation}
\end{program}


% Beschreibung GraphML
% möglich, da keine spezielle OWL-Features genutzt werden


%GraphML
% alternative Repräsentation mit dem Ziel Resourcen zu sparren (wird viel weniger Speicherplatz verbraucht)
% eignet sich gut, da der konkrete Algorithmus, der die Ähnlichkeit berechnet, nicht auf spezielle Eigenschaften von OWL angewiesen ist
% kurz diese Modellierung beschreiben.
% vlt mit nem Code-Vergleich zw beiden
% und mit nem Größenvergleich (ich habe ja beide vollständige Repräsentationen ausgerechnet)
% und Erwähnen wie viele Publikationen darzustellen sind

\subsection{Ein Ähnlichkeitsmaß für mathematische Publikationen}
% Eine gewichtete Kombination von diesen Relationen
% Begründung: warum ist die Gewichtung so ausgefallen
% 3 verschiedene Varianten machen:
%%% gleichgewichtet: für Vergleich; Gleichgewichtung macht in dem Sinne keinen Sinn, weil dafür bräuchten wir nicht zwischen verschiedenen Relationen unterscheiden
%%% 2 andere - nach Bauchgefühl
%% aber begründet: z.b. keywords, höhere gewichtung wegen \cite{Yang:2009:TRSN}, bei publikationsjahren: zeitfenster, literatur veraltet \cite{frank2009einfuehrung}
% take a look at how to compute sim rank: consider the bipartite variant - what is the difference between In-Neighbours and Out-Neighbours in my case? Should I make one?


% Idee von paper \cite{Yang:2009:TRSN} nutzen, um das Maß zu definieren

In Anlehnung an den Arbeiten von Jeh und Widom \cite{simrank2002}, Zhao, Han und Sun \cite{ZhaoHS09} und Yoon, Kim und Park \cite{DBLP:journals/corr/abs-1109-1059}
wird ein Ähnlichkeitsmaß, das semantische Relationen zwischen den Metadaten von wissenschaftlichen Publikationen berücksichtigt, vorgeschlagen.
Die Version, die hier betrachtet wird, bezieht die folgenden Metadaten eines Papers ein: Autor, Quelle, Erscheinungsjahr, Keywords und Zitationen.
Wenn jedoch weitere Metadaten in einer sinnvollen Form vorhanden sind\footnote{Beispiel hierfür wäre der schon angesprochene Titel in der Form \textit{Bag of words}},
kann der Algorithmus so abstrahiert werden, sodass diese auch in die Berechnung miteinfließen.
\\
\\
Es wird rekursiv die Ähnlichkeit zwischen jeden 2 Elementen, die der selben Kategorie angehören, aufgrund von den semantischen Relationen im modellierten semantischen Metadatengraphen für wissenschaftliche Publikationen ermittelt: jeden 2 Publikationen, jeden 2 Keywords, jeden 2 Autoren, jeden 2 Quellen und jeden 2 Erscheinungsjahren.
Dabei fließen bei der Ähnlichkeitsberechnung für 2 Publikationen die folgenden Relationen ein: (Publikation $hasKeyword$ Keyword), (Publikation $hasAuthor$ Autor), (Publikation $isPublishedIn$ Source), (Publikation $cites$ Publikation) und (Publikation $isCitedBy$ Publikation), (Publikation $wasPublishedInYear$ Erscheinungsjahr).
Bei der Ähnlichkeitsberechnung für 2 Elemente jeder anderen Kategorie werden nur die Beziehungen zwischen Elementen der entsprechenden Kategorie und Publikationen berücksichtigt, da nur solche Beziehungen im vorgeschlagenen semantischen Netz modelliert sind.
(Z.B. für die Bestimmung der Ähnlichkeit von 2 Keywords werden nur Relationen (Keyword \textit{isKeywordOf} Publikation) berücksichtigt, da Keywords in keinen anderen Relationen teilnehmen.)
\\
\\
Die folgende Definition veranschaulicht das Maß.

%Maßdefinition rekursiv
\begin{mydef}[Semantische Ähnlichkeit - rekursiv]

\[
sim(a,b) = 1 \quad \text{wenn } a=b
\]
\newline
\text{sonst}
\newline
\text{wenn a und b Publikationen:}
\[
\begin{array}{lcl}
 sim(a,b) & = & 
        \lambda_1\times\cfrac{c}{|K(a)||K(b)|}
        \sum_{i=1}^{|K(a)|} \sum_{j=1}^{|K(b)|} sim(K_i(a),K_j(b))
        \\ & + &
        \lambda_2\times\cfrac{c}{|A(a)||A(b)|}
        \sum_{i=1}^{|A(a)|} \sum_{j=1}^{|A(b)|} sim(A_i(a),A_j(b))
        \\ & + &
        \lambda_3\times\cfrac{c}{|S(a)||S(b)|}
        \sum_{i=1}^{|S(a)|} \sum_{j=1}^{|S(b)|} sim(S_i(a),S_j(b))
        \\ & + &
        \lambda_4\times\cfrac{c}{|C(a)||C(b)|}
        \sum_{i=1}^{|C(a)|} \sum_{j=1}^{|C(b)|} sim(C_i(a),C_j(b))
        \\ & + &
        \lambda_5\times\cfrac{c}{|Y(a)||Y(b)|}
        \sum_{i=1}^{|Y(a)|} \sum_{j=1}^{|Y(b)|} sim(Y_i(a),Y_j(b))
\end{array}
\]
\newline
\text{wenn a und b Elemente einer anderen Kategorie:}
\[
sim(a,b)  = 
        \cfrac{c}{|L(a)||L(b)|}
        \sum_{i=1}^{|L(a)|} \sum_{j=1}^{|L(b)|} sim(L_i(a),L_j(b))
\]
\end{mydef}

$K$ stellen alle Keyword-Relationen, $A$ alle Autor-Relationen, $S$ alle Source-Relationen, $C$ alle Zitationsrelationen und $Y$ alle Erscheinungsjahrrelationen einer Publikation dar.
Dabei wird mit $K(a)$ die Menge aller Keywords von Paper $a$ bezeichnet.
(Die Menge aller Elemente, die in Relation $hasKeyword$ zum Paper a stehen.)
$K_i(a)$ ist dann das i. Keyword von $a$.
(Analog sind $A(a)$ alle Autoren von Paper $a$, $A_i(a)$ ist der i. Autor von Paper $a$ u.s.w.)
$L(a)$ und $L(b)$ beschreiben für 2 Elemente $a$ und $b$, die der selben semantischen Kategorie angehören, die Mengen aller Elemente, die mit $a$, bzw $b$, in Relation stehen.
\newline
\newline
$\sum_{i=1}^{5} \lambda_i = 1$ sind die Gewichtungen von den verschiedenen Relationen, die die Bedeutung von den einzelnen Metadaten priorisieren; es sollten 2 verschiedene Priorisierungsreihenfolgen bestimmt und ausgewertet werden.
\newline
\newline
$c$ ist ein Dämfungsfaktor, $c\in [0..1]$; $c$ wird in Anlehnung an \cite{simrank2002}, \cite{ZhaoHS09} und \cite{DBLP:journals/corr/abs-1109-1059} bestimmt, die verschiedenen Werte ausprobieren und eine optimale Konstante in dem jeweiligen Fall vorschlagen.
\newline

Die rekursive Definition kann folgendermaßen iterativ umgeschrieben werden.
\cite{simrank2002}, \cite{ZhaoHS09} und \cite{DBLP:journals/corr/abs-1109-1059} haben gezeigt, dass die so definierten iterativen Gleichungen zu einem Fixpunkt konvergieren.

%Maßdefinition
\begin{mydef}[Semantische Ähnlichkeit - iterativ]

\[
 R_0(a,b) =
    \begin{cases}
     1 & \text{wenn } $a$ = $b$ \\
     0 & \text{sonst}\\
    \end{cases}
\]
\newline
\text{wenn a und b Publikationen:}
\[
\begin{array}{lcl}
 R_{k+1}(a,b) & = & 
        \lambda_1\times\cfrac{c}{|K(a)||K(b)|}
        \sum_{i=1}^{|K(a)|} \sum_{j=1}^{|K(b)|} R_k(K_i(a),K_j(b))
        \\ & + &
        \lambda_2\times\cfrac{c}{|A(a)||A(b)|}
        \sum_{i=1}^{|A(a)|} \sum_{j=1}^{|A(b)|} R_k(A_i(a),A_j(b))
        \\ & + &
        \lambda_3\times\cfrac{c}{|S(a)||S(b)|}
        \sum_{i=1}^{|S(a)|} \sum_{j=1}^{|S(b)|} R_k(S_i(a),S_j(b))
        \\ & + &
        \lambda_4\times\cfrac{c}{|C(a)||C(b)|}
        \sum_{i=1}^{|C(a)|} \sum_{j=1}^{|C(b)|} R_k(C_i(a),C_j(b))
        \\ & + &
        \lambda_5\times\cfrac{c}{|Y(a)||Y(b)|}
        \sum_{i=1}^{|Y(a)|} \sum_{j=1}^{|Y(b)|} R_k(Y_i(a),Y_j(b))
\end{array}
\]
\newline
\text{wenn a und b Elemente einer anderen Kategorie:}
\[
R_{k+1}(a,b)  = 
        \cfrac{c}{|L(a)||L(b)|}
        \sum_{i=1}^{|L(a)|} \sum_{j=1}^{|L(b)|} R_k(L_i(a),L_j(b))
\]
\end{mydef}
Das so definierte Maß hat die Eigenschaften Symmetrie, Monotonie, Existenz und Eindeutigkeit.
Die entsprechenden Beweise können aus \cite{ZhaoHS09} und \cite{DBLP:journals/corr/abs-1109-1059} entnommen werden.
\newline
\newline
Das vorgeschlagene Maß grenzt sich folgendermaßen von früheren Arbeiten ab:
\\
\\
SimRank und rvs-SimRank \cite{simrank2002} messen allgemeine strukturelle Ähnlichkeit in Graphstrukturen, jeweils auf die ein- bzw. auf die ausgehenden Kanten des Graphs gestützt.
\\
\\
P-Rank \cite{ZhaoHS09} verallgemeinert die zwei Maße, indem es sowohl ein- als auch ausgehenden Kanten von Informationsnetzwerken, in einer bestimmten Gewichtung, betrachtet.
\\
\\
C-Rank \cite{DBLP:journals/corr/abs-1109-1059} bezieht sich schon, im Gegensatz zu allen eben erwähnten Ansätzen, konkret auf Ähnlichkeit zwischen wissenschaftlichen Publikationen. Das Maß berücksichtigt aber nur Zitationen und unterscheidet die Richtung des Zitats nicht (d.h. unterscheidet nicht, ob Paper $A$ Paper $B$ zitiert oder anders rum).

% Notes on accuracy, decay factor and convergence:
% ------------------------------------------------

% Accuracy: C-Rank > SimRank > P-Rank > rvs-SimRank

% Number of iterations:
% SimRank converges at k = 3,
% rvs-SimRank converges at k = 5,
% P-Rank converges at k = 6,
% C-Rank converges at k = 9.

% Decay factor:
% It is obvious that the similarity score of C-Rank increases with the increase of C.
% When C = 0.2, C-Rank converges fast at k = 2.
% When C = 0.8, on the other hand, C-Rank converges at the 9-th iteration.
% When C is low, the recursive power of C-Rank is weakened such that only the papers in local or near-local neighborhood are used in similarity computation.
% When C is high, more papers in a more global neighborhood can be used in computing the similarity recursively. When C is high, therefore, the convergence takes more time.
\subsection{Mapping auf das entworfene Schema}
% technische Details
% Werkzeuge
% Designentscheidungen (wir Mappen die Sprachen jedes mal mit/doch nicht, ...) begründen

Um das vorgeschlagene Ähnlichkeitsmaß für wissenschaftliche Publikationen auswerten zu können, wird der Testdatensatz vom Zentralblatt Mathematik auf das im Kapitel \ref{subsec:modell} vorgestellte semantische Schema abgebildet.
Mit Hilfe von einem in \textit{Python} geschriebenen Parser werden die Daten vom \textit{zmath}-Datensatz sowohl in \textit{OWL}- als auch in \textit{GraphML}-Format überführt.
Wie bereits erwähnt ist die \textit{OWL}-Repräsentation der vollständigen Daten $8.9$ Gb groß, die \textit{GraphML}-Repräsentation davon ist nur $4.8$ Gb.
Genau dieser Größenunterschied ist was letztere vor allem motiviert.
\\
\\
Zudem ist jeweils noch ein Datensatz in \textit{OWL}- bzw. \textit{GraphML}-Format entstanden und zwar einer, der nur die \textit{OWL}-/\textit{GraphML}-Repräsentation von Publikationen enthält, von denen vollständige (aus der Sicht des vorgeschlagenen Ähnlichkeitsmaßes) Metadaten vorhanden sind.
Genauer gesagt enthalten diese Datensätze nur Publikationen, für die Autor, Keywords, Quelle, Erscheinungsjahr und Zitationen alle gleichzeitig vorliegen.
Diese reduzierten Datensätze beinhalten dann nur noch $1,154,950$ Publikationen.
Die eigentliche Analyse wird im Anschluss genau auf die Datensätze durchgeführt und zwar aus zweierlei Gründen.
\\
\\
Zu einem ist das Ziel dieser Arbeit, festzustellen inwiefern eine semantische Ähnlichkeitsanaylse von wissenschaftlichen Publikationen aufgrund von Metadaten und den entsprechenden Beziehungen zwischen den Publikationen und diesen Metadaten sinnvolle Ergebnisse liefert.
Hierfür ist das Vorhandensein von einem möglichst vollständigen Satz von Metadaten von besonderer Bedeutung.
Es ist logisch, dass wenn die Ähnlichkeitsberechnung eine gewichtete Kombination von 5 verschiedenen Arten von Metadaten beinhaltet, werden Papers, für die nicht alle 5 Arten von Metadaten vorliegen, in dem Sinne benachteiligt, dass sie als weniger ähnlich zu anderen Publikationen gewertet werden im Vergleich zu Publikationspaaren, für die vollständige Metadaten da sind.
\\
\\
Zum anderen wird dieses Pruning vom Datensatz wieder aus Effizienz- und Resourcenspargründen vorgenommen: mit $4.8$ Gb ist die \textit{GraphML}-Repräsentation des gesamten \textit{zmath}-Datensatzes immer noch zu umfangreich, um mit unseren Methoden effizient ausgewertet zu werden.
Selbst wenn wir die Eingangsdaten in einer Datenbank speichern und nicht in den Speicher laden müssen, haben wir immer noch die Probleme mit $O(n^4)$ Laufzeit auf 3 Millionen Knoten und der Erstellung einer Ähnlichkeitsmatrix, die im schlimmsten Fall $O(n^2)$ Platz verbraucht.

%Diese werden mit Hilfe von Ontology-Engineering-Tools und einem in $Python$ geschriebenen Parser auf ein semantisches Netz abgebildet, das in der Sprache $OWL$ modelliert ist.
% datensatz ist trimmed

% Mein Modell ist eigentlich ein semantisches Netz, worauf auch graphen-theoretische Methoden angewandt werden

% hier erwähnen, dass 2 Mappings(OWL und GraphML) entstanden sind (platzsparrgründe)
% dass auch von denen 2 Mappings entstanden sind - vom gesamten Datensatz und nur von Publikationen mit vollständigen (im Sinne meines Ähnlichkeitsmaßes) Metadaten;
% das letzte ist ok, da wir genau den Einfluss von vielen vorhandenen Metadaten auf eine Ähnlichkeitsanalyse untersuchen

