\section{Entwurf und Implementierung}

\subsection{Analyse des zugrundeliegenden Datensatzes}
% Erklaerung was das Zentralblatt Mathematik ist - siehe homepage
% Beschreibung wie der Datensatz aufgebaut ist, welche Besonderheiten sind aufgefallen
% Beispiel zeigen
% Beschreibung der Eigenschaften (bisschen statistische Analysen?)
% vlt eine Auflistung davon, welche Daten arbiträr sind (nicht immer ausgefüllt im Datensatz)

Als Ausgangspunkt für den Entwurf und Evaluierung des semantischen Ähnlichkeitsmaßes wird ein handgepflegter Datensatz vom Zentralblatt Mathematik,
\footnote{Das Zentralblatt Mathematik (ZMath) ist die größte wissenschaftliche Datenbank, die Metadaten, Abstracts und Reviews auf den Gebieten der reinen und angewandten Mathematik enthält.}
 der die Metadaten zu $2,907,086$ Publikationen enthält, eingesetzt.

Tabelle \ref{tab:metadata} gibt einen Überblick über die zu einer Publikation möglichen Einträgen.

\begin{table}[H]
\centering % used for centering table
\begin{tabular}{| c | l | l |}
		\hline
		\textbf{Bezeichner} &\textbf{Bedeutung} &\textbf{Inhalt}\\
		\hline
		\textit{:id:} & \textit{Identifier} & \textit{eindeutiger Identifier} \\
		:an: & Accession number & durch das ZMath vergebene eindeutige Identifikationsnummer\\
		:au: & Authors & die Autoren einer Publikation \\
		:ai: & Authors identified & eindeutige Stringrepräsentation von jedem Autor \\
		:ti: & Title & Überschrift der Publikation \\
		\textit{:so:} & \textit{Source} & \textit{Quelle, wo die Publikation erschienen ist} \\
		\textit{:py:} & \textit{Publication Year} & \textit{das Jahr, in dem die Publikation erschienen ist} \\
		:cc: & Classification classes & MSC Klassen, die der Publikation zugeordnet worden sind \\
        :ab/en: & Abstract English & Die Kurzzusammenfassung der Publikation auf Englisch\\
        :la: & Language & auf welcher Sprache ist die Publikation verfügbar\\
        :ut: & & englische Keywords\\
        :ci: & Citations & Arbeiten, die die Publikation zitiert\\
        :rv/en: & Reviewer & die Reviewer einer Publikation\\
		\hline
\end{tabular}
\caption{Die Metadaten vom ZMATH Datensatz. Alle \textit{Kursiveinträge} sind obligatorisch.}
\label{tab:metadata}
\end{table}

Dazu ist noch zu erwähnen, dass zu einer Publikation mehrere Autoren/Autorinnen, MSC Klassen, Sprachen, Keywords und Zitationen möglich sind.
\\
\\
Der Datensatz hat ferner die folgenden Merkmale:\\
Jede Publikation hat im Schnitt $1.68$ Autoren.
Die größte Anzahl an Wissenschaftler und Wissenschaftlerinnen, die zusammen eine Arbeit publiziert haben, ist 38.
Die produktivsten Autoren sind Paul Erdös mit $1208$ Veröffentlichungen, Edoardo Ballico ($1100$ Publikationen), Lucien Godeaux ($794$ Publikationen) und Leonard Carlitz ($735$ Publikationen).
Eine Verteilung der Autorenzahlen im $zmath$-Datensatz ist auf Abbildung \ref{fig:authorFreq} zu sehen\footnote{Publikationen, wo die Anzahl der Autoren, Zitationen, Keywords oder MSC-Klassen null ist, werden in den Diagrammen nicht berücksichtigt}.
\\
\\
Das Paper mit dem größten Literaturverzeichnis zitiert 38 andere Arbeiten.
Jede Publikation hat im Schnitt 0.27 Zitationen\footnote{wobei es davon auszugehen ist, dass die Zitationen nicht bei allen Publikationen erfasst wurden}.
Tabelle \ref{tab:citations} stellt die am öftesten zitierten Publikationen und die Anzahl ihrer Referenzen dar,
die Häufigkeitsverteilung der Zitationen im Datensatz ist in Abbildung \ref{fig:citationFreq} dargestellt.

\begin{table}[h]
\centering
\begin{tabular}{| l | p{8cm} | c |}
    \hline
    \textbf{:an:} & \textbf{ Titel/Quelle} & \textbf{Anzahl Referenzen}\\
    \hline
    $Zbl 0707.68001$ & IJCA I-89. International joint conference on artificial intelligence, Detroit, MI, USA, August 20-25, 1989. Proceedings. Vol. 1 u. 2.&257\\
    \hline
    $Zbl 0425.00034$ & Proceedings of the 1978 IEEE conference on decision and control, including the 17th symposium on adaptive processes. IEEE Control Systems Society, January 10-12, 1979, Islandia Hyatt House Hotel, San Diego, California. & 212\\
    \hline
    $Zbl 0741.68016$ & IJCAI 91, Proceedings of the 12th International Conference on Artificial Intelligence. Sydney, Australia, 24-30 August 1991. Vol. 1-2. & 183\\
    \hline
    $Zbl 0657.00005$ & Proceedings of the International Congress of Mathematicians (ICM), August 3-11, 1986, Berkeley, California. Volumes $1+2$. & 159\\
    \hline
    $Zbl 0624.00010$ & Nonlinear oscillations. Proceedings of the 11th International Conference on Nonlinear Oscillations, Budapest, August 17-23, 1987. & 156\\
    \hline
\end{tabular}
\caption{Die am häufigsten zitierten Papers}
\label{tab:citations}
\end{table}

Im Durchschnitt wurden pro Publikation 3 Keywords vergeben.
Die maximale Anzahl von Keywords für eine Arbeit ist 219, die nächst große - 162.
Tabelle \ref{tab:keywords} beinhaltet die am häufigsten vergebenen Keywords.
Häufigkeitsverteilung der Keywords kann Abbildung \ref{fig:keywordFreq} entnommen weden.

\begin{table}[h]
\centering
\begin{tabular}{| l | c |}
		\hline
		\textbf{Keyword} &\textbf{Anzahl Papers} \\
		\hline
		convergence & $18,872$\\
		stability & $16,766$ \\
		functional analysis & $15,049$ \\
		fluid machanics & $14,185$ \\
		numerical examples & $13,874$\\
	    \hline
\end{tabular}
\caption{Die häufigsten Keywords}
\label{tab:keywords}
\end{table}


Es gibt Papers auf 69 verschiedenen Sprachen.
$2,897,259$ der Publikationen wurden auf einer Sprache veröffentlicht, $9,588$ auf 2, 33 auf 4 und eine Publikation ist auf 7 Sprachen verfügbar.
Die am häufigsten vorkommenden Sprachen sind: Englisch (mit $2,370,288$ Publikationen), Russisch (mit $180,335$), Französisch ($100,575$), Deutsch ($91,510$) und Chinesisch ($77,924$).
\\
\\
Im Durchschnitt hat jede Arbeit 2 MSC Klassen, die Arbeit mit den meisten Klassen hat 61.
$2,594,068$ Publikationen haben mindestens eine MSC Klasse.
Die am häufigsten vergebenen MSC Klassen sind $68U99$ (Compuer Science -> Computing methodologies and applications), $80A20$ (Classical thermodynamics, heat transfer -> Heat and mass transfer, heat flow), $93C05$ (Systems theory; control -> Control systems -> Linear systems) und $68Q25$ (Computer Science -> Theory of computing -> Analysis of algorithms and problem complexity).
Abbildung \ref{fig:mscClassFreq} stellt die Verteilung der MSC-Klassen im Datensatz dar.
\\
\\
Die Arbeiten, die der Datensatz enthält, sind in 89 verschiedenen Jahren veröffentlicht worden.
Der früheste Eintrag (eine Arbeit vom schweizerischen Mathematiker Leonard Euler) stammt vom Jahr 1796.
Es gibt auch jeweils eine Publikation von den Jahren 1879, 1914, 1924 und 1930.
1931 ist mit 4041 Veröffentlichungen das erste Jahr, das mehr oder weniger vollständig im Datensatz vermerkt ist.
Das produktivste Jahr bis jetzt war 2008 mit $102,319$ Veröffentlichungen.


\begin{figure}
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.3]{../data/statistics/authorFreq.png}
        \caption{Autorenverteilung}
        \label{fig:authorFreq}
    \end{subfigure}
    \qquad
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.3]{../data/statistics/citationFreq.png}
        \caption{Zitationsverteilung}
        \label{fig:citationFreq}
    \end{subfigure}
    \newline
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.3]{../data/statistics/keyWordFreq.png}
        \caption{Keywordverteilung}
        \label{fig:keywordFreq}
    \end{subfigure}
    \qquad
    \begin{subfigure}[h]{0.5\textwidth}
        \centering
        \includegraphics[scale=0.3]{../data/statistics/mscClassFreq.png}
        \caption{Verteilung der MSC-Klassen}
        \label{fig:mscClassFreq}
    \end{subfigure}
    \caption{Verteilungen einiger Metadaten im zmath-Datensatz}
    \label{fig:frequencies}
\end{figure}

\subsection{Modellierung des Publikationnetzwerks}
\label{subsec:modell}
% Wie sieht es aus?
% Welche Überlegungen gab es bei der Designentscheidung? Warum hab ich an Stellen, wo mehrere Ansätze möglich waren genau das gewählt?
% Was könnte vlt anders/besser realisiert werden
% Vlt technische Details/Grenzen/Eckdaten (Laufzeit, Speicherplatz, etc)
% Vlt Werkzeuge

% Motivation für die Modellierung:
% Ontology of Science z.b hat nen anderen Fokus;
% modelliert eine ganze Domäne von wissenschaftlichen Akteuren, Ereignissen, Einrichtungen,..
% das Modell, das sie bietet, ist für Ähnlichkeitsanalysen zwischen wissenschaftlichen Arbeiten nicht geeignet.
% Was Ontology of Science zu einer Publikation modelliert: diverse Unterklassen (Report, Thesis, ...), Author, Topic, Publication Year
% Was Ontology of Science zu einer Publikation NICHT modelliert (ist aber wichtig): Classification, Title, Keywords, Source (klar gekennzeichnet und in Relation zu der Publikation stehend), Zitationsrelationen

% Die Klassen einzeln durchgehen + die Relationen: erklären warum genau diese relevant sind und modelliert werden sollen
% erklären welche Metadaten genau für diese Arbeit von Relevanz sind
% zukünftige Möglichkeiten der Auswertung (Abstract, Title können auch nach weiterer Verabeitung ausgewertet werden) - mehr dazu in Evaluation oder Ausblick

Als Grundlage für die Ermittlung der Ähnlichkeit zwischen zwei wissenschaftlichen Publikationen sollte eine Modellierung dieser und der dazu gehörigen Metadaten in der Form eines Netzwerks realisiert werden.
\\
\\
Die bereits existierende \textit{Ontology of Science} \cite{ontosci} (vgl. Kapitel \ref{sec:semanticRepr}) scheint auf dem ersten Blick ein gutes Modell für Publikationen zu sein, hat jedoch einen ganz anderen Fokus.
Sie modelliert eine ganze Domäne von wissenschaftlichen Akteuren, Ereignissen, Einrichtungen, Arbeiten und die dazwischen bestehenden Beziehungen.
Sie bietet ferner eine recht detaillierte Aufteilung von wissenschaftlichen Publikationen in Unterkategorien (z.B. \textit{Technical report}, \textit{Book}, \textit{Thesis}, \textit{Journal article}, etc.).
Dennoch eignet sich das Modell eher schlecht für Ähnlichkeitsanalysen zwischen Publikationen aufgrund von Metadaten.
Viele Einheiten, die für solche Analysen von großem Interesse wären, werden durch die \textit{Ontology of Science} nicht erfasst.
Einige Beispiele hierfür sind Metadaten wie Klassifikationscodes, Keywords oder Zitationen.
\\
\\
Aus diesen Gründen schlägt die aktuelle Arbeit ein Informationsnetzwerk für Publikationen vor.
Das allgemeine Schema dieses Publikationnetzwerks ist auf Abbildung \ref{fig:schemePubs} veranschaulicht.
Wie bereits in Kapitel \ref{sec:knowledgeRep} erwähnt, wird dabei jede Publikation und jedes dazugehörige Metadatum als einen Knoten modelliert.
Jeder dieser Knoten hat das Attribut \textit{Klasse}, das bezeichnet, ob es sich um eine Publikation, einen Autor, ein Keyword, ein Erscheinungsjahr, einen Klassifikationscode, eine Sprache, einen Editor, einen Reviewer oder eine Quelle handelt.
Ferner können die Knoten, die Publikationen repräsentieren, auch eines oder mehrere der folgenden Attribute haben: \textit{Id}, \textit{Abstract}, \textit{TitleString} oder \textit{Accession Number} (letzteres ist eine für den \textit{zmath}-Datensatz spezifische Identifikationsnummer).
\smallskip
Die gelabelten Kanten dieses Netzes sind die Relationen zwischen einem Paper und seinen Metadaten.
Mögliche Werte dieses Relationattributs einer Kante sind \textit{hasAuthor}, \textit{hasKeyword}, \textit{hasClassificationCode}, \textit{wasPublishedInYear}, \textit{cites}, \textit{isPublshedIn}, \textit{hasPublicationLanguage}, \textit{hasKeywordlanguage}, \textit{hasTitleLanguage}, \textit{hasEditor}, \textit{hasReviewer}, \textit{hasTitle}, \textit{isCoauthorWith},
je nachdem welchen Klassen die Endknoten dieser Kante angehören.

\begin{figure}[hp]
    \centering
    \includegraphics[angle=90,scale=0.6]{../deps/publications_ontology_relations.png}
    \caption{Informationsnetzwerk für wissenschaftliche Publikationen: allgemeines Schema}
    \label{fig:schemePubs}
\end{figure}
\smallskip
Eine besondere Designentscheidung ist, dass die drei Relationen \textit{hasKeywordLanguage}, \textit{hasPublicationLanguage} und \textit{hasTitleLanguage} einzeln modelliert sind.
Der Hintergrundgedanke dabei ist, dass eine Publikation oder die entsprechenden Metadaten: Keyword und Titel, auf mehreren Sprachen vorliegen können.
Diese Definition erlaubt dann, dass z.B. der englische Begriff \textit{graph theory} und das deutsche Wort \textit{Graphentheorie} auf das selbe Keyword abgebildet werden können.
Das kann ein zukünftiges sprachunabhängiges Verfahren zur Ähnlichkeitsberechnung unterstützen.
\\
\\
Eine andere auffällige Besonderheit ist die Tatsache, dass sowohl Knoten mit dem Attribut \textit{Klasse=Title}, die in Relation \textit{hasTitle} mit Knoten der Klasse \textit{Publication} stehen, als auch das Attribut \textit{TitleString} bei Knoten der Klasse \textit{Publication} modelliert werden.
Diese Entscheidung beruht auf der Idee, dass ein Knoten der Klasse \textit{Publication} seinen exakten Titel im Attribut \textit{TitleString} speichern kann.
Aus diesem Stringdatenwert können dann später die Schlüsselbegriffe extrahiert werden und als ein \textit{Bag of words}\footnote{Bag of words bezeichnet in den Feldern der Information Retrieval und Natural Language Processing eine ungeordnete Menge von Wörtern} auf ein Knoten der Klasse \textit{Title} abgebildet werden.
Somit können Titel verschiedener Publikationen, die die gleichen bedeutsamen Begriffe enthalten, auf das selbe Knoten der Klasse \textit{Title} abgebildet werden.
Dieser Ansatz wäre für eine Ähnlichkeitsanalyse viel sinnvoller als ein einfaches Stringmatching auf zwei exakten Titel zu machen oder die String-Edit-Distance zwischen diesen zu bestimmen.
Das ist jedoch eine Möglichkeit, die die aktuelle Arbeit nicht mehr realisiert und die zukünftig näher untersucht werden kann.
% zukünftige Möglichkeiten der Auswertung (Abstract, Title können auch nach weiterer Verabeitung ausgewertet werden) - mehr dazu in Evaluation oder Ausblick
\\
\\
Das vorgeschlagene Netzwerkschema ist möglichst allgemein gehalten, damit verschiedene Datensätze, die wissenschaftliche Publikationen beinhalten, darauf abgebildet werden können.
Bei Bedarf kann das Schema unkompliziert erweitert werden.
\\
\\
Die Modellierung des Publikationnetzwerks wurde mit \textit{GraphML}\footnote{\textit{GraphML} ist eine auf \textit{XML} basierende Beschreibungssprache für Graphen.
Sie unterstützt ungerichtete, gerichtete, gemischte, Hyper- und Multigraphen.
Ferner können sowohl Knoten als auch Kanten beliebige Attribute zugeordnet werden.
Eine vollständige Dokumentation von \textit{GraphML} ist unter graphml.graphdrawing.org/primer/graphml-primer.htm zu finden.
} realisiert.
Der folgende Codeausschnitt soll die \textit{GraphML}-Repräsentation der Beispielspublikation \textit{Publication\_123456} mit ihren Autor \textit{John Smith} und 2 Keywords \textit{graph theory} und \textit{shortest path} veranschaulichen.

\begin{program}
\input{diagrams/pub_graphml_example}
\caption{Die \textit{GraphML}-Repräsentation}
\end{program}


\subsection{Ein Ähnlichkeitsmaß für mathematische Publikationen}
% Eine gewichtete Kombination von diesen Relationen
% Begründung: warum ist die Gewichtung so ausgefallen
% 3 verschiedene Varianten machen:
%%% gleichgewichtet: für Vergleich; Gleichgewichtung macht in dem Sinne keinen Sinn, weil dafür bräuchten wir nicht zwischen verschiedenen Relationen unterscheiden
%%% 2 andere - nach Bauchgefühl
%% aber begründet: z.b. keywords, höhere gewichtung wegen \cite{Yang:2009:TRSN}, bei publikationsjahren: zeitfenster, literatur veraltet \cite{frank2009einfuehrung}
% take a look at how to compute sim rank: consider the bipartite variant - what is the difference between In-Neighbours and Out-Neighbours in my case? Should I make one?


% Idee von paper \cite{Yang:2009:TRSN} nutzen, um das Maß zu definieren

In Anlehnung an die Arbeiten von Jeh und Widom \cite{simrank2002}, Zhao, Han und Sun \cite{ZhaoHS09} und Yoon, Kim und Park \cite{DBLP:journals/corr/abs-1109-1059}
wird ein Ähnlichkeitsmaß, das die Relationen zwischen den Metadaten von wissenschaftlichen Publikationen berücksichtigt, vorgeschlagen.
Analog zu diesen Arbeiten, die strukturelle Ähnlichkeitsmaße für Informationsnetzwerke definieren, basiert das vorgeschlagene Maß auch auf der Idee ``zwei Objekte sind ähnlich, wenn sie mit ähnlichen Objekten verbunden sind''.
Im Gegensatz zu \textit{SimRank} \cite{simrank2002}, \textit{P-Rank} \cite{ZhaoHS09} und \textit{C-Rank} \cite{DBLP:journals/corr/abs-1109-1059} jedoch berücksichtigt dieses Maß nicht nur Publikationen, sondern auch dazugehörige Metadaten.
Die Version, die hier betrachtet wird, bezieht die folgenden Metadaten eines Papers ein: Autor, Quelle, Erscheinungsjahr, Keywords und Zitationen.
Wenn jedoch weitere Metadaten in einer sinnvollen Form vorhanden sind\footnote{Beispiel hierfür wäre der schon angesprochene Titel in der Form \textit{Bag of words}},
kann der Algorithmus so abstrahiert werden, sodass diese auch in die Berechnung miteinfließen.
\\
\\
Es wird rekursiv die Ähnlichkeit zwischen je 2 Knoten derselben Klasse aufgrund der Relationen im modellierten Publikationsnetz ermittelt: je 2 Publikationen, je 2 Keywords, je 2 Autoren, je 2 Quellen und je 2 Erscheinungsjahren.
Dabei fließen bei der Ähnlichkeitsberechnung für 2 Publikationen die folgenden Relationen ein: (Publikation $hasKeyword$ Keyword), (Publikation $hasAuthor$ Autor), (Publikation $isPublishedIn$ Source), (Publikation $cites$ Publikation) und (Publikation $isCitedBy$ Publikation), (Publikation $wasPublishedInYear$ Erscheinungsjahr).
Bei der Ähnlichkeitsberechnung für 2 Elemente jeder anderen Klasse werden nur die Beziehungen zwischen Elementen der entsprechenden Klasse und Publikationen berücksichtigt, da nur solche Beziehungen im vorgeschlagenen Netz modelliert sind.
(Z.B. für die Bestimmung der Ähnlichkeit von 2 Keywords wird die Relation (Keyword \textit{isKeywordOf} Publikation) berücksichtigt.)
\\
\\
Mit $sim(a,b)$ wird der Ähnlichkeitswert für 2 Elemente $a$ und $b$ bezeichnet.
Dabei gilt stets $0 \leq sim(a,b) \leq 1$.
Die grundlegende Idee bei der Definition ist, dass ein Element am meisten ähnlich zu sich selbst ist.
\\
\\
Die folgende Definition veranschaulicht das Maß.

%Maßdefinition rekursiv
\begin{mydef}[Semantische Ähnlichkeit - rekursiv]

\[
sim(a,b) = 1 \quad \text{wenn } a=b
\]
\newline
\text{sonst}
\newline
\text{wenn a und b Publikationen:}
\[
\begin{array}{lcl}
 sim(a,b) & = & 
        \lambda_1\times\cfrac{c}{|K(a)||K(b)|}
        \sum_{i=1}^{|K(a)|} \sum_{j=1}^{|K(b)|} sim(K_i(a),K_j(b))
        \\ & + &
        \lambda_2\times\cfrac{c}{|A(a)||A(b)|}
        \sum_{i=1}^{|A(a)|} \sum_{j=1}^{|A(b)|} sim(A_i(a),A_j(b))
        \\ & + &
        \lambda_3\times\cfrac{c}{|S(a)||S(b)|}
        \sum_{i=1}^{|S(a)|} \sum_{j=1}^{|S(b)|} sim(S_i(a),S_j(b))
        \\ & + &
        \lambda_4\times\cfrac{c}{|C(a)||C(b)|}
        \sum_{i=1}^{|C(a)|} \sum_{j=1}^{|C(b)|} sim(C_i(a),C_j(b))
        \\ & + &
        \lambda_5\times\cfrac{c}{|Y(a)||Y(b)|}
        \sum_{i=1}^{|Y(a)|} \sum_{j=1}^{|Y(b)|} sim(Y_i(a),Y_j(b))
\end{array}
\]
\newline
\text{wenn a und b aus sonstiger Klasse:}
\[
sim(a,b)  = 
        \cfrac{c}{|L(a)||L(b)|}
        \sum_{i=1}^{|L(a)|} \sum_{j=1}^{|L(b)|} sim(L_i(a),L_j(b))
\]
\end{mydef}

$K$ stellen alle Keyword-Relationen, $A$ alle Autor-Relationen, $S$ alle Source-Relationen, $C$ alle Zitationsrelationen und $Y$ alle Erscheinungsjahrrelationen einer Publikation dar.
Dabei wird mit $K(a)$ die Menge aller Keywords von Paper $a$ bezeichnet.
(Die Menge aller Elemente, die in Relation $hasKeyword$ zum Paper a stehen.)
$|K(a)|$ ist die Anzahl der Elemente, die dieser Menge angehören.
$K_i(a)$ ist dann das i. Keyword von $a$.
(Analog sind $A(a)$ alle Autoren von Paper $a$, $|A(a)|$ ist deren Anzahl, $A_i(a)$ ist der i. Autor von Paper $a$ u.s.w.)
$L(a)$ und $L(b)$ beschreiben für 2 Elemente $a$ und $b$, die der selben Klasse angehören, die Mengen aller Elemente, die mit $a$, bzw $b$, in Relation stehen (also alle Nachbarn von $a$ bzw. $b$).
\\
\\
$\sum_{i=1}^{5} \lambda_i = 1$ sind die Gewichtungen der verschiedenen Relationen, die die Bedeutung der einzelnen Metadaten für eine Publikation priorisieren; es sollten 2 verschiedene Priorisierungsreihenfolgen bestimmt und ausgewertet werden.
\\
\\
$c$ ist ein Dämpfungsfaktor, $c\in [0..1]$;
$c$ wird in Anlehnung an \cite{Lizorkin2010} bestimmt, die eine Genauigkeitsschätzung für \textit{SimRank} abhängig von der Wahl der Anzahl der Iterationen und des Werts des Dämpfungsfaktors berechnen.
\\
\\
Um Division durch $0$ zu vermeiden, wird für den Fall, dass z.B. $K(a)=\emptyset$ oder $K(b)=\emptyset$ die ganze Komponente
$\lambda_x\times\cfrac{c}{|K(a)||K(b)|}\sum_{i=1}^{|K(a)|} \sum_{j=1}^{|K(b)|} sim(K_i(a),K_j(b)) = 0$ gesetzt.
\\
\\
Das so definierte Maß hat die Eigenschaften Symmetrie, Monotonie, Existenz und Eindeutigkeit.
Die entsprechenden Beweise können aus \cite{ZhaoHS09} und \cite{DBLP:journals/corr/abs-1109-1059} entnommen werden.
\\

Die rekursive Definition kann folgendermaßen iterativ umgeschrieben werden.
\cite{simrank2002}, \cite{ZhaoHS09} und \cite{DBLP:journals/corr/abs-1109-1059} haben gezeigt, dass die so definierten iterativen Gleichungen zu einem Fixpunkt konvergieren.

%Maßdefinition
\begin{mydef}[Semantische Ähnlichkeit - iterativ]

\[
 R_0(a,b) =
    \begin{cases}
     1 & \text{wenn } $a$ = $b$ \\
     0 & \text{sonst}\\
    \end{cases}
\]
\newline
\text{wenn a und b Publikationen:}
\[
\begin{array}{lcl}
 R_{k+1}(a,b) & = & 
        \lambda_1\times\cfrac{c}{|K(a)||K(b)|}
        \sum_{i=1}^{|K(a)|} \sum_{j=1}^{|K(b)|} R_k(K_i(a),K_j(b))
        \\ & + &
        \lambda_2\times\cfrac{c}{|A(a)||A(b)|}
        \sum_{i=1}^{|A(a)|} \sum_{j=1}^{|A(b)|} R_k(A_i(a),A_j(b))
        \\ & + &
        \lambda_3\times\cfrac{c}{|S(a)||S(b)|}
        \sum_{i=1}^{|S(a)|} \sum_{j=1}^{|S(b)|} R_k(S_i(a),S_j(b))
        \\ & + &
        \lambda_4\times\cfrac{c}{|C(a)||C(b)|}
        \sum_{i=1}^{|C(a)|} \sum_{j=1}^{|C(b)|} R_k(C_i(a),C_j(b))
        \\ & + &
        \lambda_5\times\cfrac{c}{|Y(a)||Y(b)|}
        \sum_{i=1}^{|Y(a)|} \sum_{j=1}^{|Y(b)|} R_k(Y_i(a),Y_j(b))
\end{array}
\]
\newline
\text{wenn a und b aus sonstiger Klasse:}
\[
R_{k+1}(a,b)  = 
        \cfrac{c}{|L(a)||L(b)|}
        \sum_{i=1}^{|L(a)|} \sum_{j=1}^{|L(b)|} R_k(L_i(a),L_j(b))
\]
\end{mydef}
Das vorgeschlagene Maß grenzt sich folgendermaßen von früheren Arbeiten ab:
\\
\\
SimRank und rvs-SimRank \cite{simrank2002} messen allgemeine strukturelle Ähnlichkeit in Graphstrukturen, jeweils auf die ein- bzw. auf die ausgehenden Kanten des Graphs gestützt.
\\
\\
P-Rank \cite{ZhaoHS09} verallgemeinert die zwei Maße, indem es sowohl ein- als auch ausgehenden Kanten von Informationsnetzwerken, in einer bestimmten Gewichtung, betrachtet.
\\
\\
C-Rank \cite{DBLP:journals/corr/abs-1109-1059} bezieht sich schon, im Gegensatz zu allen eben erwähnten Ansätzen, konkret auf Ähnlichkeit zwischen wissenschaftlichen Publikationen. Das Maß berücksichtigt aber nur Zitationen.

% Notes on accuracy, decay factor and convergence:
% ------------------------------------------------

% Accuracy: C-Rank > SimRank > P-Rank > rvs-SimRank

% Number of iterations:
% SimRank converges at k = 3,
% rvs-SimRank converges at k = 5,
% P-Rank converges at k = 6,
% C-Rank converges at k = 9.

% Decay factor:
% It is obvious that the similarity score of C-Rank increases with the increase of C.
% When C = 0.2, C-Rank converges fast at k = 2.
% When C = 0.8, on the other hand, C-Rank converges at the 9-th iteration.
% When C is low, the recursive power of C-Rank is weakened such that only the papers in local or near-local neighborhood are used in similarity computation.
% When C is high, more papers in a more global neighborhood can be used in computing the similarity recursively. When C is high, therefore, the convergence takes more time.
\subsection{Mapping auf das entworfene Schema}
% technische Details
% Werkzeuge
% Designentscheidungen (wir Mappen die Sprachen jedes mal mit/doch nicht, ...) begründen

Um das vorgeschlagene Ähnlichkeitsmaß für wissenschaftliche Publikationen auswerten zu können, wird der Testdatensatz vom Zentralblatt Mathematik auf das im Kapitel \ref{subsec:modell} vorgestellte semantische Schema abgebildet.
Mit Hilfe von einem in \textit{Python} geschriebenen Parser werden die Daten vom \textit{zmath}-Datensatz sowohl in \textit{OWL}- als auch in \textit{GraphML}-Format überführt.
Die \textit{OWL}-Repräsentation der vollständigen Daten ist wie bereits erwähnt ca. doppelt so groß wie die \textit{GraphML}-Repräsentation, weshalb im weiteren Verlauf \textit{GraphML} Anwendung findet.
\\
\\
Zudem ist jeweils noch ein Datensatz in \textit{OWL}- bzw. \textit{GraphML}-Format entstanden, der nur die \textit{OWL}-/\textit{GraphML}-Repräsentation von Publikationen enthält, von denen vollständige (aus der Sicht des vorgeschlagenen Ähnlichkeitsmaßes) Metadaten vorhanden sind.
Genauer gesagt enthalten diese Datensätze nur Publikationen, für die Autor, Keywords, Quelle, Erscheinungsjahr und Zitationen alle gleichzeitig vorliegen.
Diese reduzierten Datensätze beinhalten $1,154,950$ Publikationen.%knapp 1Gb
%Wie bereits angedeutet, beinhaltet der von dieser Arbeit benutzte Testdatensatz die Metadaten zu $2,907,086$ Publikationen.
%Eine \textit{OWL}-Repräsentation der vollständigen Daten wird $8.9$ Gb groß, dagegen ist die \textit{GraphML}-Repräsentation davon nur $4.8$ Gb.
Die eigentliche Analyse wird im Anschluss auf dem verkleinerten Datensatz durchgeführt.
\\
\\
%Kommentar von Susi: die andere Formulierung ist zu lang.
Dieses Vorgehen basiert einerseits auf einem effizienteren und sparsameren Umgang mit Ressourcen.
Andererseits sollen Publikationen mit im Ähnlichkeitsmaß verwendeten fehlenden Metadaten in der Berechnung nicht benachteiligt werden.
Es sollte dennoch in einer späteren Phase evaluiert werden, inwiefern fehlende Metadaten eine korrekte Ausführung und Ähnlichkeitsberechnung beeinflussen.
\\
\\
%Zu einem ist das Ziel dieser Arbeit, festzustellen inwiefern eine semantische Ähnlichkeitsanaylse von wissenschaftlichen Publikationen aufgrund von Metadaten und den entsprechenden Beziehungen zwischen den Publikationen und diesen Metadaten sinnvolle Ergebnisse liefert.
%Hierfür ist das Vorhandensein von einem möglichst vollständigen Satz von Metadaten von besonderer Bedeutung.
%Es ist logisch, dass wenn die Ähnlichkeitsberechnung eine gewichtete Kombination von 5 verschiedenen Arten von Metadaten beinhaltet, werden Papers, für die nicht alle 5 Arten von Metadaten vorliegen, in dem Sinne benachteiligt, dass sie als weniger ähnlich zu anderen Publikationen gewertet werden im Vergleich zu Publikationspaaren, für die vollständige Metadaten da sind.
\\
\\
%Zum anderen wird dieses Pruning vom Datensatz wieder aus Effizienz- und Resourcenspargründen vorgenommen: mit $4.8$ Gb ist die \textit{GraphML}-Repräsentation des gesamten \textit{zmath}-Datensatzes immer noch zu umfangreich, um mit unseren Methoden effizient ausgewertet zu werden.
%Selbst wenn wir die Eingangsdaten in einer Datenbank speichern und nicht in den Speicher laden müssen, haben wir immer noch die Probleme mit $O(n^4)$ Laufzeit auf 3 Millionen Knoten und der Erstellung einer Ähnlichkeitsmatrix, die im schlimmsten Fall $O(n^2)$ Platz verbraucht.

%-------------------------------------------------------------
% Mein Modell ist eigentlich ein semantisches Netz, worauf auch graphen-theoretische Methoden angewandt werden

% hier erwähnen, dass 2 Mappings(OWL und GraphML) entstanden sind (platzsparrgründe)
% dass auch von denen 2 Mappings entstanden sind - vom gesamten Datensatz und nur von Publikationen mit vollständigen (im Sinne meines Ähnlichkeitsmaßes) Metadaten;
% das letzte ist ok, da wir genau den Einfluss von vielen vorhandenen Metadaten auf eine Ähnlichkeitsanalyse untersuchen

