\section{Evaluation}

\subsection{\textbf{Komplexitätsanalyse des Algorithmus}}
Wie in Kapitel \ref{subsec:simMeasure} erläutert, kann der rekursive Ähnlichkeitsalgorithmus als ein iterativer, zum Fixpunkt konvergierender Algorithmus dargestellt werden.
\textit{Algorithmus} \ref{alg:derAlg} veranschaulicht das iterative Verfahren für die Berechnung der semantischen Ähnlichkeit in einem Publikationsnetzwerk $G$.

\begin{program2}
%\begin{algorithmic}
\[
\begin{array}{ll}
\textbf{Input:} & \text{Publikationsnetzwerk \textit{G};}\\
& \lambda_1, \lambda_2, \lambda_3, \lambda_4, \lambda_5 \text{- Gewichtungen der jeweils Keywords-, Autoren-, Quellen-,}\\
& \text{Zitation- und Erscheinungsjahrrelationen eines Papers,} \sum_{i=1}^{5} \lambda_i = 1;\\
& \text{der Dämpfungsfaktor \textit{c};}\\
& \text{und die Anzahl der Iterationen \textit{k}}\\
\textbf{Output:} & \text{Der Ähnlichkeitswert } s(a,b), \forall a,b \in G \text{ und \textit{a}, \textit{b} Knoten der selben Art}
\end{array}
\]
\caption{Der iterative Algorithmus}
\label{alg:derAlg}
\end{program2}
\begin{Verbatim}[commandchars=\\\{\}, fontsize=\small, numbers=left, numbersep=3pt,codes={\catcode`$=3\catcode`_=8}]
\textbf{foreach} \begin{math}a{\in}G\end{math} \textbf{do} \hspace{5cm}\textbf{/* Initialization */}\\
    \textbf{foreach} \begin{math}b{\in}G\end{math} \textbf{do}\\
        \textbf{if} \begin{math}a==b\end{math} \textbf{then} \begin{math}R(a,b)=1\end{math}\\
        \textbf{else} \begin{math}R(a,b)=0\end{math}\\
\textbf{while} \begin{math}(k>0)\end{math} \textbf{do} \hspace{6.2cm}\textbf{/* Iteration */}\\
    \begin{math}k{\longleftarrow}k-1 \end{math}\\
    \textbf{foreach} \begin{math}a{\in}G\end{math} \textbf{do}\\
        \textbf{foreach} \begin{math}b{\in}G\end{math} \textbf{do}\\
            \textbf{if} \begin{math}a[Class]{==}b[Class]\end{math} \textbf{and} \begin{math}a[Class]{==}"Publication"\end{math} \textbf{then}\\
                \begin{math}key{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}k_a{\in}K(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}k_b{\in}K(b)\end{math} \textbf{do}\\
                        \begin{math}key{\longleftarrow}key{+}R(k_a,k_b)\end{math}\\
                \begin{math}R_{new}(a,b){\longleftarrow}\lambda_1*\cfrac{c*key}{|K(a)||K(b)|} \end{math}\\

                \begin{math}auth{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}a_a{\in}A(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}a_b{\in}A(b)\end{math} \textbf{do}\\
                        \begin{math}auth{\longleftarrow}auth{+}R(a_a,a_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\lambda_2*\cfrac{c*auth}{|A(a)||A(b)|} \end{math}\\

                \begin{math}sour{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}s_a{\in}S(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}s_b{\in}S(b)\end{math} \textbf{do}\\
                        \begin{math}sour{\longleftarrow}sour{+}R(s_a,s_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\lambda_3*\cfrac{c*sour}{|S(a)||S(b)|} \end{math}\\

                \begin{math}cit{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}c_a{\in}C(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}c_b{\in}C(b)\end{math} \textbf{do}\\
                        \begin{math}cit{\longleftarrow}cit{+}R(c_a,c_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\lambda_4*\cfrac{c*cit}{|C(a)||C(b)|} \end{math}\\

                \begin{math}year{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}y_a{\in}Y(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}y_b{\in}Y(b)\end{math} \textbf{do}\\
                        \begin{math}year{\longleftarrow}year{+}R(y_a,y_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\lambda_5*\cfrac{c*year}{|Y(a)||Y(b)|} \end{math}\\

            \textbf{else if} \begin{math}a[Class]{==}b[Class]\end{math} \textbf{and} \begin{math}a[Class]{!=}"Publication"\end{math} \textbf{then}\\
                \begin{math}link{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}l_a{\in}L(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}l_b{\in}L(b)\end{math} \textbf{do}\\
                        \begin{math}link{\longleftarrow}link{+}R(l_a,l_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\cfrac{c*link}{|L(a)||L(b)|} \end{math}\\

            \textbf{else}\\
                \begin{math}R_{new}(a,b){=}0\end{math} /* a and b are from different classes */\\
    \textbf{foreach} \begin{math}a{\in}G\end{math} \textbf{do} \hspace{6.2cm}\textbf{/* Update */}\\
        \textbf{foreach} \begin{math}b{\in}G\end{math} \textbf{do}\\
            \begin{math}R(a,b){=}R_{new}(a,b)\end{math}\\
\textbf{return} \begin{math}R(*,*)\end{math}
\end{Verbatim}
%\caption{Der iterative Algorithmus}
%\end{program2}

\begin{comment}
\begin{algorithm}
\caption{your caption for this algorithm}
\label{your label for references later in your document}
\begin{algorithmic}
\forall{$a \in G $}
\end{algorithmic}
\end{algorithm}
\end{comment}

% Pseudo code
% speicher- und laufzeitkomplexität klären
% Laufzeit $\mathcal{O}(n^4)$ - 4 for-Schleifen
% Speicher $\mathcal{O}(n^2)$ - symmetrische Matrix, die die Ähnlichkeitswerte für jedes Paar (Publikationen/Knoten) speichert

\subsection{Testläufe}
% Vergleich: Laufzeit und Speicherverbrauch der alten strukturellen Maße (SimRank, P-Rank, C-Rank)
% auf wie vielen Daten wurden diese ausgewertet und wie lange hats gedauert? was für parameter hatte das testsystem?
% -----------------
% Accuracy estimate of SimRank \cite{Lizorkin2010}: 10000 Nodes - 46 Stunden (1GB RAM, 2.1GHz CPU)

% P-Rank
%------
%Heterogenous IN: 218930 Nodes;
%Mit den beschriebenen Parametern ihres Systems (2.4 GHz CPU und 2 GB RAM) können sie auf keinen Fall alles im Memory laden...
%Bzw steht nirgendswo wie lange sie für gebraucht haben
%--------
%Homogenous IN: 21740 Nodes
% All our experiments are performed on an Intel PC with a 2.4GHz CPU, 2GB memory, running Redhat Fedora Core 4.
% One more experiment with syntetic data: 100 000 Nodes


%C-Rank: 23795 Publications
% All our experiments were performed on an Intel PC with Quad Core 2.67GHz CPU, running Windows 2008;
% RAM unknown
% time: unknown



% Was genau habe ich ausgerechnet?

%Um das vorgeschlagene Ähnlichkeitsmaß für wissenschaftliche Publikationen auswerten zu können, wird der Testdatensatz vom Zentralblatt Mathematik auf das im Kapitel \ref{subsec:modell} vorgestellte Graphenschema abgebildet.
%Mit Hilfe von einem in \textit{Python} geschriebenen Parser werden die Daten vom \textit{zmath}-Datensatz in \textit{GraphML}-Format überführt.
%Die \textit{GraphML}-Repräsentation der vollständigen Daten ist ca. $4.8$ Gb groß.

% 1. Trimming des Datensatzes: auf $1$ Gb - nur die Publikationen mit vollständigen Metadaten, $1,154,950$ Publikationen
% -- nicht wirklich berechenbar in vernünftiger Zeit (siehe Komplexitätsanalyse)
% 2. Trimming des Datensatzes: 3095 Publikationen mit vollständigen Metadaten (alle Publikationen im Datensatz, die vor dem Jahr 1975 veröffentlicht wurden);
% wie lange hat das gedauert??
% P1: 14911.1054752 Sec
% P2: 14732.8429248 Sec
% P3: 14984.688808 Sec
% Crank: 13935.943378 Sec

% So werden nicht Zitationsrelationen zu späteren Arbeiten verloren (eine frühere Arbeit kann eine spätere nicht zitieren)
% andererseit aber werden Relationen verloren, da der Algorithmus auf dem Gesamtpublikationsnetzwerk rechnet (also Werte, die über rausgeschnittenen Knoten propagiert wurden, gehen verloren)
% -- also eine Auswertung "wie gut ist das Ähnlichkeitsmaß" wird vermutlich nicht sehr sinnvolle Ergebnisse liefern



% Parameters of the test system:
%Hardware Overview:
%    Model Name: Mac Pro
%    Model Identifier: MacPro4,1
%    Processor Name: Quad-Core Intel Xeon
%    Processor Speed: 2,93 GHz
%    Number Of Processors: 2
%    Total Number Of Cores: 8
%    L2 Cache (per core): 256 KB
%    L3 Cache (per processor): 8 MB
%    Memory: 14 GB
%    Processor Interconnect Speed: 6.4 GT/s

%System Software Overview:
%    System Version: Mac OS X 10.6.8 (10K549)
%    Kernel Version: Darwin 10.8.0
%    Boot Volume: Macintosh HD
%    Boot Mode: Normal

\subsection{Bestimmung der Parameter}
% wie werden die lambdas gewählt? warum?
% wie wird c gewählt? warum (simRank optimierungspaper)

% Notes on accuracy, decay factor and convergence:
% ------------------------------------------------

% It is obvious that the similarity score of C-Rank increases with the increase of C
% When C is low, the recursive power of C-Rank is weakened such that only the papers in local or near-local neighborhood are used in similarity computation.
% When C is high, more papers in a more global neighborhood can be used in computing the similarity recursively. When C is high, therefore, the convergence takes more time.
% \cite{Lizorkin2010} : folgende Gleichung gilt: s(a,b) - R_k(a,b) <= C^(k+1) gibt uns die Accuracy in Abhängigkeit von C und k
% wichtig wie das gewählt wird, Ähnlichkeitswerte sind zwischen 0 und 1, relativ hohe Genauigkeit ist wichtig!
% gewählte Parameter: c=0.6, k=7: mehr vom globalen Netz fließt in die Berechnung mit ein; erzielte Genauigkeit: 0.01679616
% (zum Vergleich SimRank nutzt originell c=0.8 und k= 5, was eine Genauigkeit von 0.26 ergibt, relativ ungenau!


\subsection{Auswertung der Ergebnisse}
% Macht das, was rauskommt, Sinn?

% Vergleich gegen die MSC-Klassen
% Vergleich mit einem rein bibliometrischen Verfahren (bibliographische Kopplung / SimRank/ ..)
% Entwickle 3 Varianten und vergleich sie: mit unterschiedlichen Gewichtung von den verschiedenen Relationen

% Clustering über die entstandene Ähnlichkeitsmatrix für alle Verfahren (C-Rank + alle 3 Parametrisierungen)
% Idee: Vergleich entstandene Cluster mit den ursprünglich vergebenen MSC-Klassen: wenn die MSC-Klassifizierung gut abgebildet, gutes Clustering
% MSC Klassen werden bis zur Top-Level Klassen aggregiert
% Wahl des Clusteringverfahrens

% Ergebnisse: Durchschnittswerte von Entropy, Purity, Silhouette-Koeffizient, Verteilung
%% Kurze Definition von Entropy, Purity und Silhouette
%% Beschreibung/Vergleich der Ergebnisse (für 3095 Publikationen und 64 Cluster)
% -- SemSim schneidet schon besser als C-Rank ab (C-Rank packt alles in den selben Cluster)
% -- Schlussfolgerungen: Entweder war das Clusteringverfahren doof oder aber ist das Trimming vom Datensatz dumm und es können keine adäquate Ergebnisse geliefert werden
