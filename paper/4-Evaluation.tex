\section{Evaluation}

\subsection{\textbf{Komplexitätsanalyse des Algorithmus}}
Wie in Kapitel \ref{subsec:simMeasure} erläutert, kann der rekursive Ähnlichkeitsalgorithmus als ein iterativer, zum Fixpunkt konvergierender Algorithmus dargestellt werden.
Algorithmus \ref{alg:derAlg} veranschaulicht das iterative Verfahren für die Berechnung der semantischen Ähnlichkeit in einem Publikationsnetzwerk $G$.

\begin{program2}
%\begin{algorithmic}
\[
\begin{array}{ll}
\textbf{Input:} & \text{Publikationsnetzwerk \textit{G};}\\
& \lambda_1, \lambda_2, \lambda_3, \lambda_4, \lambda_5 \text{- Gewichtungen der jeweils Keywords-, Autoren-, Quellen-,}\\
& \text{Zitation- und Erscheinungsjahrrelationen eines Papers,} \sum_{i=1}^{5} \lambda_i = 1;\\
& \text{der Dämpfungsfaktor \textit{c};}\\
& \text{und die Anzahl der Iterationen \textit{k}}\\
\textbf{Output:} & \text{Der Ähnlichkeitswert } s(a,b), \forall a,b \in G \text{ und \textit{a}, \textit{b} Knoten der selben Art}
\end{array}
\]
\caption{Der iterative Algorithmus}
\label{alg:derAlg}
\end{program2}
\begin{Verbatim}[commandchars=\\\{\}, fontsize=\small, numbers=left, numbersep=3pt,codes={\catcode`$=3\catcode`_=8}]
\textbf{foreach} \begin{math}a{\in}G\end{math} \textbf{do} \hspace{5cm}\textbf{/* Initialization */}\\
    \textbf{foreach} \begin{math}b{\in}G\end{math} \textbf{do}\\
        \textbf{if} \begin{math}a==b\end{math} \textbf{then} \begin{math}R(a,b)=1\end{math}\\
        \textbf{else} \begin{math}R(a,b)=0\end{math}\\
\textbf{while} \begin{math}(k>0)\end{math} \textbf{do} \hspace{6.2cm}\textbf{/* Iteration */}\\
    \begin{math}k{\longleftarrow}k-1 \end{math}\\
    \textbf{foreach} \begin{math}a{\in}G\end{math} \textbf{do}\\
        \textbf{foreach} \begin{math}b{\in}G\end{math} \textbf{do}\\
            \textbf{if} \begin{math}a[Class]{==}b[Class]\end{math} \textbf{and} \begin{math}a[Class]{==}"Publication"\end{math} \textbf{then}\\
                \begin{math}key{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}k_a{\in}K(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}k_b{\in}K(b)\end{math} \textbf{do}\\
                        \begin{math}key{\longleftarrow}key{+}R(k_a,k_b)\end{math}\\
                \begin{math}R_{new}(a,b){\longleftarrow}\lambda_1*\cfrac{c*key}{|K(a)||K(b)|} \end{math}\\

                \begin{math}auth{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}a_a{\in}A(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}a_b{\in}A(b)\end{math} \textbf{do}\\
                        \begin{math}auth{\longleftarrow}auth{+}R(a_a,a_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\lambda_2*\cfrac{c*auth}{|A(a)||A(b)|} \end{math}\\

                \begin{math}sour{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}s_a{\in}S(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}s_b{\in}S(b)\end{math} \textbf{do}\\
                        \begin{math}sour{\longleftarrow}sour{+}R(s_a,s_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\lambda_3*\cfrac{c*sour}{|S(a)||S(b)|} \end{math}\\

                \begin{math}cit{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}c_a{\in}C(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}c_b{\in}C(b)\end{math} \textbf{do}\\
                        \begin{math}cit{\longleftarrow}cit{+}R(c_a,c_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\lambda_4*\cfrac{c*cit}{|C(a)||C(b)|} \end{math}\\

                \begin{math}year{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}y_a{\in}Y(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}y_b{\in}Y(b)\end{math} \textbf{do}\\
                        \begin{math}year{\longleftarrow}year{+}R(y_a,y_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\lambda_5*\cfrac{c*year}{|Y(a)||Y(b)|} \end{math}\\

            \textbf{else if} \begin{math}a[Class]{==}b[Class]\end{math} \textbf{and} \begin{math}a[Class]{!=}"Publication"\end{math} \textbf{then}\\
                \begin{math}link{\longleftarrow}0 \end{math}\\
                \textbf{foreach} \begin{math}l_a{\in}L(a)\end{math} \textbf{do}\\
                    \textbf{foreach} \begin{math}l_b{\in}L(b)\end{math} \textbf{do}\\
                        \begin{math}link{\longleftarrow}link{+}R(l_a,l_b)\end{math}\\
                \begin{math}R_{new}(a,b){+=}\cfrac{c*link}{|L(a)||L(b)|} \end{math}\\

            \textbf{else} pass\\
                /* a and b are from different classes */\\
    \textbf{foreach} \begin{math}a{\in}G\end{math} \textbf{do} \hspace{6.2cm}\textbf{/* Update */}\\
        \textbf{foreach} \begin{math}b{\in}G\end{math} \textbf{do}\\
            \begin{math}R(a,b){=}R_{new}(a,b)\end{math}\\
\textbf{return} \begin{math}R(*,*)\end{math}
\end{Verbatim}
%\caption{Der iterative Algorithmus}
%\end{program2}

%\begin{algorithm}
%\caption{your caption for this algorithm}
%\label{your label for references later in your document}
%\begin{algorithmic}
%\forall{$a \in G $}
%\end{algorithmic}
%\end{algorithm}

% Beschreiben bisschen
% Theoretische Grenzen: Speicher, Zeit
% wie siehts praktisch aus? symmetrische Sparsematrix (Python dictionary) mit nur den Nichtnull-Einträgen wird gespeichert
% Laufzeit: die Ähnlichkeit für verschiedenartige Knoten wird nicht weiter verfolgt, da wird auch was geprunnt.
%%----------- Eigentlich sind die Sachen unten für den Ausblick!
% wenn G zu groß, kann mans extern, außerhalb des Hauptspeichers auslagern (z.b. Graphdatenbank) (die Ähnlichkeitsmatrix, egal welche Struktur für ihre Repräsentation gewählt wird, wird erstmal einfachshalber im Arbeitsspeicher behalten
% das eigentliche (größere) Problem ist die Laufzeit -- es können Verfahren gesucht werden, um die zu optimieren / Teile des Algorithmus zu parallelisieren

Algorithmus \ref{alg:derAlg} wird entsprechend Definition \ref{def:semSim} initialisiert (Zeilen 1--4).
Für jedes Paar Knoten, die der selben Kategorie angehören (jede zwei Publikationen, jede zwei Keywords, jede zwei Autoren, jede zwei Quellen und jede zwei Erscheinungsjahre),
wird dann in der (k+1)-te Iteration die Ähnlichkeit, $R_{new}(a,b)$, berechnet, indem die Ähnlichkeit für diese Knoten in der k-ten Iteration, $R(a,b)$, aktualisiert wird (Zeilen 7--45).
Bei der Berechnung der Ähnlichkeit zwischen zwei Publikationen fließen alle ihre Metadaten (Keywords, Autoren, Quelle, Zitationen und Erscheinungsjahr) ein (Zeilen 9--38).
Bei der Berechnung der Ähnlichkeit zwischen zwei Knoten jeder anderen Kategorie fließen nur Publikationen ein, da Keywords, Autoren, Quellen und Erscheinungsjahre in dem modellierten Netzwerk nur Publikationen als Nachbarn haben (Zeilen 40--45).
Die Ähnlichkeit von zwei Knoten aus verschiedenen Kategorien ist stets 0 und wird von dem Algorithmus nicht aktualisiert (Zeilen 47--48).
Für weitere Iterationen wird dann $R$ durch $R_{new}$ ersetzt (Zeilen 49--51).
\\
\\
Für ein Publikationsnetzwerk G mit n Knoten, ist die Speicherkomplexität des Algorithmus \ref{alg:derAlg} $\mathcal{O}(n^2)$.
Obwohl die dieser Arbeit zugrundeliegende Implementierung nicht die explizite $n{\times}n$ Matrix, sondern nur die Hälfte davon (die Matrix ist symmetrisch, $s(a,b){=}s(b,a)$) und davon nur die nichtnull-Einträge speichert, wird mit steigender Anzahl von Publikationen/Knoten insgesamt in G der Speicherbedarf quadratisch steigen.
\\
\\
Algorithmus \ref{alg:derAlg} braucht im schlimmsten Fall $\mathcal{O}(n^4)$ Zeit, denn für die Ähnlichkeitsberechnung jeder zwei Knoten werden rekursiv auch alle Knotenpaare aus ihren Nachbarn betrachtet.
Selbst wenn ein Pruning basierend auf den Knotenarten durchgeführt wird (Ähnlichkeit für Knoten a und b, die nicht der selben Kategorie angehören, wird nicht berechnet), ändert sich die generelle Laufzeitkomplexität nicht.%oder??

\subsection{Bestimmung der Parameter}
\label{subsec:params}
Im Folgenden wird diskutiert, welche Auswirkung die Werte der Parameter $c$, $k$ und $\lambda_i$ haben und wie sie am geeignetsten gewählt werden können.
\\
\\
Der Dämpfungsfaktor $c$ bestimmt wie stark sich das globale Publikationsnetzwerk auf die Ähnlichkeit zwischen zwei konkreten Knoten $a$ und $b$ auswirkt.
Wenn $c$ relativ klein ist, tragen weiter entfernte von $a$ und $b$ Knoten viel weniger zu deren Ähnlichkeit bei.
Es wird nur die lokale Nachbarschaft von $a$ und $b$ in deren Ähnlichkeitsberechnung miteinbezogen.
Mit größerem $c$ fließt mehr von dem globalen Netzwerk bei der rekursiven Berechnung in den Ähnlichkeitswert zweier Knoten ein.
Demzufolge braucht der iterative Algorithmus bei größerem $c$ mehr Zeit zum Konvergieren.
\\
\\
\cite{Lizorkin2010} beweisen für \textit{SimRank}, dass der Unterschied zwischen den theoretischen und iterativen Ähnlichkeitswerten für zwei Knoten $a$ und $b$ in der Anzahl der durchgeführten Iterationen exponentiell sinkt.
Sie stellen die folgende Ungleichung auf: $s(a,b)-R_k(a,b) \leq c^{k+1}$ .
Also bestimmt der Wert $c^{k+1}$ die Genauigkeit, die der iterative \textit{SimRank}-Algorithmus nach $k$ Iterationen erreicht.
Aufgrund dieser Schlussfolgerung wählt die vorliegende Arbeit die Werte $c=0.6$ und $k=7$ für die Berechnung der semantischen Ähnlichkeit.
Diese ergeben für den iterativen Algorithmus eine Genauigkeit von $0.6^{7+1}=0.0168$.
% Überzeugend erklären: Lässt sich auch hier anwenden, alternativ, Beweis im Appendix
\\
\\
Kapitel \ref{subsec:simMeasure} definiert bereits, dass die Summe der Gewichtungen aller verschiedenen Metadaten $1$ ergibt, $\sum_{i=1}^{5} \lambda_i = 1$.
Diese Normalisierung stellt sicher, dass kein Ähnlichkeitswert größer $1$ werden kann.
Diese Arbeit berechnet die semantsiche Ähnlichkeit mit drei verschiedenen Gewichtungen und wertet im folgenden Kapitel aus, welche die Optimalste ist.
Die $\lambda$-s sind in diesen Gewichtungen folgendermaßen verteilt:
\begin{table}[H]
\centering
\begin{tabular}{l c c c}
		%\hline
		\textbf{Parameter} &\textbf{Gewichtung 1} &\textbf{Gewichtung 2} &\textbf{Gewichtung 3} \\
		%\hline
		$\lambda_1$, Keywords & $0.5$ & $0.2$ & $0.4$\\
		$\lambda_2$, Autoren & $0.1$ & $0.2$ & $0.3$\\
		$\lambda_3$, Quellen & $0.1$ & $0.2$ & $0.1$\\
		$\lambda_4$, Zitationen & $0.2$ & $0.2$ & $0.1$\\
		$\lambda_5$, Erscheinungsjahre & $0.1$ & $0.2$ & $0.1$\\
	    %\hline
\end{tabular}
%\caption{Metadatengewichtungen}
\label{tab:parametrization}
\end{table}
% brauche ich mehr dazu, warum ich die so gewählt hab?


% wie werden die lambdas gewählt? warum?
% wie wird c gewählt? warum (simRank optimierungspaper)

% Notes on accuracy, decay factor and convergence:
% ------------------------------------------------

% It is obvious that the similarity score of C-Rank increases with the increase of C
% When C is low, the recursive power of C-Rank is weakened such that only the papers in local or near-local neighborhood are used in similarity computation.
% When C is high, more papers in a more global neighborhood can be used in computing the similarity recursively. When C is high, therefore, the convergence takes more time.
% \cite{Lizorkin2010} : folgende Gleichung gilt: s(a,b) - R_k(a,b) <= C^(k+1) gibt uns die Accuracy in Abhängigkeit von C und k
% wichtig wie das gewählt wird, Ähnlichkeitswerte sind zwischen 0 und 1, relativ hohe Genauigkeit ist wichtig!
% gewählte Parameter: c=0.6, k=7: mehr vom globalen Netz fließt in die Berechnung mit ein; erzielte Genauigkeit: 0.01679616
% (zum Vergleich SimRank nutzt originell c=0.8 und k= 5, was eine Genauigkeit von 0.26 ergibt, relativ ungenau!


\subsection{Testläufe}
Die früheren strukturellen Ähnlichkeitsmaße \textit{SimRank}, \textit{P-Rank} und \textit{C-Rank} haben die selbe Laufzeit- und Speicherkomplexität wie die hier vorgeschlagene semantische Ähnlichkeit: $\mathcal{O}(n^4)$ bzw. $\mathcal{O}(n^2)$ im schlimmsten Fall \cite{simrank2002} \cite{ZhaoHS09} \cite{DBLP:journals/corr/abs-1109-1059}.
Sie wurden auf den folgenden Datensätzen angewandt.
Jeh und Widom werten \textit{SimRank} auf zwei Datensätzen mit jeweils $278,628$ und $1003$ Elementen aus.
Sie machen Angaben weder zu den Parametern des benutzten Systems noch zu der Zeit, die sie für die Durchführung der Berechnungen gebraucht haben \cite{simrank2002}.
Lizorkin et al., die diversve Ansätze für die Optimierung von \textit{SimRank} vorschlagen, werten ebenfalls den nicht optimierten \textit{SimRank}-Algorithmus aus.
Auf ihrem Testsystem mit $1$Gb RAM und $2.1$GHz CPU braucht dieser bei $10,000$ Elementen 46 Stunden \cite{Lizorkin2010}.
Die Autoren von \textit{P-Rank} wenden ihren Algorithmus auf drei Testdatensätzen mit jeweils $218,930$, $21,740$ und $100,000$ Elementen an \cite{ZhaoHS09}.
Ihr Testsystem hatte $2$Gb RAM und $2.4$GHz CPU, was andeutet, dass sie die ausgewerteten Informationsnetzwerke extern gelagert und nicht in den Speicher geladen haben.
Sie machen ebenfalls keine Angaben zu der gebrauchten Zeit.
Yoon, Kim und Park werten \textit{C-Rank} auf einem Datensatz mit $23,795$ Publikationen aus.
Ihr System hatte $2.67$GHz CPU, Speicherangaben machen sie keine, auch keine Angaben zu der gebrauchten Zeit \cite{DBLP:journals/corr/abs-1109-1059}.

% Vergleich: Laufzeit und Speicherverbrauch der alten strukturellen Maße (SimRank, P-Rank, C-Rank)
% auf wie vielen Daten wurden diese ausgewertet und wie lange hats gedauert? was für parameter hatte das testsystem?
% -----------------
% Accuracy estimate of SimRank \cite{Lizorkin2010}: 10000 Nodes - 46 Stunden (1GB RAM, 2.1GHz CPU)

% P-Rank
%------
%Heterogenous IN: 218930 Nodes;
%Mit den beschriebenen Parametern ihres Systems (2.4 GHz CPU und 2 GB RAM) können sie auf keinen Fall alles im Memory laden...
%Bzw steht nirgendswo wie lange sie für gebraucht haben
%--------
%Homogenous IN: 21740 Nodes
% All our experiments are performed on an Intel PC with a 2.4GHz CPU, 2GB memory, running Redhat Fedora Core 4.
% One more experiment with syntetic data: 100 000 Nodes


%C-Rank: 23795 Publications
% All our experiments were performed on an Intel PC with Quad Core 2.67GHz CPU, running Windows 2008;
% RAM unknown
% time: unknown

Das System, auf dem der von dieser Arbeit vorgeschlagene Algorithmus für Berechnung der semantischen Ähnlichkeit zwischen Publikationen ausgeführt wird, verfügt über $2.93$GHz CPU und $14$Gb Arbeitsspeicher.
Die einzige Arbeit, die konkrete Hinweise für die Laufzeit der Algorithmen für strukturelle Ähnlichkeit in Informationsnetzwerken in der Praxis gibt, ist \cite{Lizorkin2010}.
Da diese Algorithmen die selbe Laufzeitkomplexität wie die hier vorgeschlagene semantische Ähnlichkeit haben, ist es nicht schwer zu folgern, dass die Berechnung der Ähnlichkeiten für den gesamten \textit{zmath}-Datensatz, mit $2,907,086$ Publikationen, auf diesem Testsystem unpraktikabel ist.
\\
\\
Aus diesem Grund wird der \textit{zmath}-Datensatz zunächst folgendermaßen gekürzt.
Es werden nur die Publikationen betrachtet, für die die vollständigen Metadaten, die in die Berechnung der semantischen Ähnlichkeit einfließen, verfügbar sind.
Das ergibt $1,154,950$ Publikationen und $5,518,500$ Knoten insgesamt für das modellierte Publikationsnetzwerk.
Die Ähnlichkeiten für diesen verkürzten Datensatz wurden ebenfalls als nicht in realistischer Zeit berechenbar gewertet.
Um eine Auswertung der Ergebnisse des vorgeschlagenen Algorithmus durchführen zu können, werden nur noch die Publikationen aus dem \textit{zmath}-Datensatz betrachtet, die bis einschließlich 1975 veröffentlicht worden sind.
Das ergibt ein Publikationsnetzwerk mit $3095$ Publikationen und $15,994$ Knoten insgesamt.
Für die Berechnung der Ähnlichkeiten in diesem Publikationsnetzwerk mit dem semantischen Ähnlichkeitsmaß wurden bei den oben beschriebenen Parametern ($k=7$ Iterationen und $c=0.6$ Dämpfungsfaktor) und Systemeigenschaften im Durchschnitt 4 Stunden und 8 Minuten gebraucht
(Die semantische Ähnlichkeit wurde für die drei verschiedenen Verteilungen der Gewichtungen $\lambda$, die in Kapitel \ref{subsec:params} beschrieben wurden, berechnet).
% wie lange hat das gedauert??
% P1: 14911.1054752 Sec
% P2: 14732.8429248 Sec
% P3: 14984.688808 Sec
% Crank: 13935.943378 Sec

% So werden nicht Zitationsrelationen zu späteren Arbeiten verloren (eine frühere Arbeit kann eine spätere nicht zitieren)
% andererseit aber werden Relationen verloren, da der Algorithmus auf dem Gesamtpublikationsnetzwerk rechnet (also Werte, die über rausgeschnittenen Knoten propagiert wurden, gehen verloren)
% -- also eine Auswertung "wie gut ist das Ähnlichkeitsmaß" wird vermutlich nicht sehr sinnvolle Ergebnisse liefern


% Was genau habe ich ausgerechnet?

%Um das vorgeschlagene Ähnlichkeitsmaß für wissenschaftliche Publikationen auswerten zu können, wird der Testdatensatz vom Zentralblatt Mathematik auf das im Kapitel \ref{subsec:modell} vorgestellte Graphenschema abgebildet.
%Mit Hilfe von einem in \textit{Python} geschriebenen Parser werden die Daten vom \textit{zmath}-Datensatz in \textit{GraphML}-Format überführt.
%Die \textit{GraphML}-Repräsentation der vollständigen Daten ist ca. $4.8$ Gb groß.

% Parameters of the test system:
%Hardware Overview:
%    Model Name: Mac Pro
%    Model Identifier: MacPro4,1
%    Processor Name: Quad-Core Intel Xeon
%    Processor Speed: 2,93 GHz
%    Number Of Processors: 2
%    Total Number Of Cores: 8
%    L2 Cache (per core): 256 KB
%    L3 Cache (per processor): 8 MB
%    Memory: 14 GB
%    Processor Interconnect Speed: 6.4 GT/s

%System Software Overview:
%    System Version: Mac OS X 10.6.8 (10K549)
%    Kernel Version: Darwin 10.8.0
%    Boot Volume: Macintosh HD
%    Boot Mode: Normal

\subsection{Auswertung der Ergebnisse}
% Macht das, was rauskommt, Sinn?

% Vergleich gegen die MSC-Klassen
% Vergleich mit einem rein bibliometrischen Verfahren (bibliographische Kopplung / SimRank/ ..)
% Entwickle 3 Varianten und vergleich sie: mit unterschiedlichen Gewichtung von den verschiedenen Relationen

% Clustering über die entstandene Ähnlichkeitsmatrix für alle Verfahren (C-Rank + alle 3 Parametrisierungen)
% Idee: Vergleich entstandene Cluster mit den ursprünglich vergebenen MSC-Klassen: wenn die MSC-Klassifizierung gut abgebildet, gutes Clustering
% MSC Klassen werden bis zur Top-Level Klassen aggregiert
% Wahl des Clusteringverfahrens

% Ergebnisse: Durchschnittswerte von Entropy, Purity, Silhouette-Koeffizient, Verteilung
%% Kurze Definition von Entropy, Purity und Silhouette
%% Beschreibung/Vergleich der Ergebnisse (für 3095 Publikationen und 64 Cluster)
% -- SemSim schneidet schon besser als C-Rank ab (C-Rank packt alles in den selben Cluster)
% -- Schlussfolgerungen: Entweder war das Clusteringverfahren doof oder aber ist das Trimming vom Datensatz dumm und es können keine adäquate Ergebnisse geliefert werden
